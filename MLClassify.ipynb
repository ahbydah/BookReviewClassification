{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Aubrey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]     C:\\Users\\Aubrey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_treebank_pos_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Aubrey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Aubrey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import PunktSentenceTokenizer, sent_tokenize, word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "nltk.download('punkt')\n",
    "nltk.download('maxent_treebank_pos_tagger')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy \n",
    "import sklearn\n",
    "import random\n",
    "from pprint import pprint\n",
    "import string\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "from sklearn.svm import SVC, NuSVC, LinearSVC\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getData():\n",
    "    \n",
    "    data = pd.read_csv(\"BookReviews.csv\", encoding = 'latin1')\n",
    "    \n",
    "    #without specifying \"encoding\" paramter, threw a \"Unicode Decode Error\"\n",
    "    #help found at:\n",
    "    #https://stackoverflow.com/questions/18171739/unicodedecodeerror-when-reading-csv-file-in-pandas-with-python\n",
    "    \n",
    "    \n",
    "    data = data.sample(frac = 1).reset_index(drop = True)\n",
    "    \n",
    "    \n",
    "    #df.sample() returns a random sample of the data in df. The kwarg frac specifies the fraction of the total df\n",
    "    #     that you wish to sample. Then frac = 1 samples the entire df.\n",
    "    #Then, df.reset_index() resets the index of the df, and the kwarg \"drop = True\" \n",
    "    #     prevents the old index being stored as a column in the df\n",
    "    #****help found at:\n",
    "    #https://stackoverflow.com/questions/29576430/shuffle-dataframe-rows\n",
    "    \n",
    "    data = data.loc[:, ~data.columns.str.contains('^Unnamed')]  #had several (about 4) columns titles \"Unnamed\"\n",
    "    \n",
    "    return data\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addPOS(df, ps):\n",
    "    \n",
    "    taggedTxt = []\n",
    "    \n",
    "    for i in df.index:\n",
    "        \n",
    "        txt = str(df.iloc[i])  #I had problems where this was a float, which doesn't make much sense\n",
    "        txt = txt.lower()\n",
    "        tggd = tag_txt(txt, ps)\n",
    "        taggedTxt.append(tggd)\n",
    "        \n",
    "    column = pd.Series(taggedTxt, index = df.index)\n",
    "    return column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tag_txt(txt, ps):\n",
    "    #is passed a string of raw text\n",
    "    \n",
    "    #this is just nltk's English Stop words with a couple things deleted, like \"didn't\", \"couldn't\" and their variations    \n",
    "    custStopWords = ['to', 'further', 'ma', 'a', 'no',  'or', 'ours', 'once', 'before', 'out', \"doesn't\", \n",
    "                      've', 'm', \"you've\", \"needn't\", 'you', 'not', 'so', 'off', 'under', 'most', 'which', \n",
    "                      'more', 'ourselves', 'about', 'down', 'isn', 'they', 'his', \"she's\", 'only', 'how', \n",
    "                      'had', 'again', 'by', 'after', 'shan', 'their', 'some', \"hasn't\", 'mustn', 'yours', \n",
    "                      'is', 'who', 'we', 'because', \"you'll\", 'it', 'has', 'both', 'here', \"don't\", 'than', \n",
    "                      'through', 'any', 'did', 'its', 'own', 'being', 'all', 'yourself', 'needn', 'd', 'o', \n",
    "                      \"weren't\",  'itself', 'what', 're', 'my', 'there', 'ain', 'i', \"isn't\", \"aren't\", 'if', \n",
    "                      'll', 'wasn', 'of', 'your', 'an',  'over', 'wouldn', 'y', \"mightn't\", 'between', 'mightn',\n",
    "                      \"hadn't\", 's', 'on', 'while', 'from', 'have', \"shan't\", 'then', \"mustn't\", 'will', 'below',\n",
    "                      'where', 'been', 'same', 'don', 'myself', 'until', 'other', 'doesn', 'but', 'above', 'can', \n",
    "                      'for', 'and', 'against', \"you'd\", 'him', 'does', 'into', 'are', 'these', 'few', 'himself', \n",
    "                      'aren', \"wasn't\", 'at', 'too', \"should've\", 'should', 'those', \"that'll\", 'me', 'hasn', 'shouldn',\n",
    "                      'themselves', 'weren', 'our', 'as', 'be', \"it's\", 'the', 'was', 'up', 'hadn', 'am',\n",
    "                      'this', 'yourselves', 'that', \"you're\", 'having', 'each', 'do', 'she', 'them', 'very',\n",
    "                      'nor', 'he', 'whom', 'now', 'won', 'during', 'her', 'hers', 'were', 'just', 'with', \n",
    "                      'why', \"wouldn't\", 'when', 'herself', \"won't\", \"shouldn't\", 'such', 'doing', 'in', 'theirs']\n",
    "    \n",
    "    trashPOStags = ['NNP', 'NNPS', 'PRP', 'PRP$', 'WP$', 'WP', 'WDT']\n",
    "\n",
    "    taggedLst= []\n",
    "    \n",
    "\n",
    "    toked = PunktSentenceTokenizer().tokenize(txt)  #tokenized into sentences\n",
    "    \n",
    "    for s in toked: \n",
    "        \n",
    "        words = word_tokenize(s)  #tokenize into words\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        words = [words[i] for i in range(len(words)) if words[i] not in string.punctuation]\n",
    "        \n",
    "        words = nltk.pos_tag(words) #creates a list of (word, posTag) pairs\n",
    "\n",
    "        \n",
    "        words = [(ps.stem(word[0]), word[1]) for word in words if word[0] not in custStopWords] #stem the words.\n",
    "\n",
    "        for word in words:  #word -> (word, pos)\n",
    "            if not word[1] in trashPOStags: #if not a proper noun, etc\n",
    "                taggedLst.append(word)\n",
    "    \n",
    "\n",
    "    return taggedLst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getFeatsCART(series):\n",
    "    \n",
    "    valList = []\n",
    "    \n",
    "    \n",
    "    for i in series.index:\n",
    "        sample = series.iloc[i]\n",
    "        stemTxt = \"\"\n",
    "        for w in sample:\n",
    "            stemTxt += str(w[0])\n",
    "            stemTxt += \" \"\n",
    "        valList.append(stemTxt)\n",
    "    stemTxtCol = pd.Series(valList)\n",
    "    \n",
    "    return stemTxtCol\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "reviews = getData()\n",
    "ps = PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews.loc[:, \"pos_stem\"] = addPOS(reviews.loc[:, 'text'], ps)\n",
    "#addPOS() takes a Series, and returns a Series containing processed, tagged words as a new column of the df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews.loc[:, \"stemTxtCol\"] = getFeatsCART(reviews.loc[:, 'pos_stem'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "txtList = [reviews.loc[:, \"stemTxtCol\"].iloc[i] \n",
    "           for i in reviews.loc[:, \"stemTxtCol\"].index]\n",
    "\n",
    "piv = (len(txtList) // 4) * 3\n",
    "\n",
    "trainTxt = txtList[:piv]\n",
    "testTxt = txtList[piv:]\n",
    "\n",
    "targArr = np.zeros(len(txtList))\n",
    "\n",
    "for i in range(len(txtList)):\n",
    "    if reviews.iloc[i].loc[\"label\"] == \"i\":\n",
    "        targArr[i] = 1\n",
    "        \n",
    "        \n",
    "trTarg = targArr[:piv]\n",
    "tsTarg = targArr[piv:]\n",
    "        \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtParams =  {'vect__ngram_range': [(1, i+2) for i in range(4)],\n",
    "            'clf__max_depth': [i+2 for i in range(15)]+[None],\n",
    "            \"clf__min_samples_leaf\": [(i+1) for i in range(10)], \n",
    "            \"clf__max_features\": [(i+5) for i in range(10)]+[None]}\n",
    "\n",
    "\n",
    "#'vect__max_features': [i+5 for i in range(10)]+[None],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dt_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', \n",
    "                      DecisionTreeClassifier())])\n",
    "\n",
    "\n",
    "randSearch = RandomizedSearchCV(estimator = dt_clf, \n",
    "                   param_distributions = dtParams,\n",
    "                   n_iter = 100, cv = 3, verbose=2,\n",
    "                   random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "randSearch.fit(trainTxt, trTarg)\n",
    "\n",
    "best_random = randSearch.best_estimator_\n",
    "\n",
    "_ = best_random.fit(trainTxt, trTarg)\n",
    "\n",
    "predicted = best_random.predict(testTxt)\n",
    "\n",
    "# gs_clf = GridSearchCV(text_clf, param_grid = dtParams, cv=3, iid=False, n_jobs=-1)\n",
    "\n",
    "# gs_clf = gs_clf.fit(trainTxt, trTarg)\n",
    "\n",
    "print(randSearch.best_score_)\n",
    "print(randSearch.best_params_)\n",
    "print()\n",
    "print()\n",
    "# _ = gs_clf.best_estimator_.fit(trainTxt, trTarg)\n",
    "# predicted = gs_clf.best_estimator_.predict(testTxt)\n",
    "\n",
    "print(np.mean(predicted == tsTarg))\n",
    "print()\n",
    "print(\"classification report\")\n",
    "print(metrics.classification_report(tsTarg, predicted))\n",
    "print()\n",
    "print(\"confusion mtx\")\n",
    "print(metrics.confusion_matrix(tsTarg, predicted))\n",
    "\n",
    "# print()\n",
    "# for i in range(len(predicted)):\n",
    "#     if predicted[i] != tsTarg[i]:\n",
    "#         print(tsTarg[i])\n",
    "#         print(testTxt[i])\n",
    "#         print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgdParams = {'vect__max_features': [i+5 for i in range(15)]+[None],\n",
    "             'vect__ngram_range': [(1, i+2) for i in range(4)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__alpha': (1e-2, 1e-3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sgd_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', \n",
    "                      SGDClassifier())])\n",
   
    "\n",
    "\n",
    "\n",
    "randSearch = RandomizedSearchCV(estimator = sgd_clf, \n",
    "                   param_distributions = sgdParams,\n",
    "                   n_iter = 100, cv = 3, verbose=2,\n",
    "                   random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "randSearch.fit(trainTxt, trTarg)\n",
    "\n",
    "best_random = randSearch.best_estimator_\n",
    "\n",
    "_ = best_random.fit(trainTxt, trTarg)\n",
    "\n",
    "predicted = best_random.predict(testTxt)\n",
    "\n",
    "print(randSearch.best_score_)\n",
    "print(randSearch.best_params_)\n",
    "print()\n",
    "print()\n",
    "print(np.mean(predicted == tsTarg))\n",
    "print()\n",
    "print(\"classification report\")\n",
    "print(metrics.classification_report(tsTarg, predicted))\n",
    "print()\n",
    "print(\"confusion mtx\")\n",
    "print(metrics.confusion_matrix(tsTarg, predicted))\n",
    "\n",
    
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfParams = {\"clf__n_estimators\": [i+1 for i in range(15)], \n",
    "                    \"clf__max_depth\": [i+1 for i in range(15)], \n",
    "                   \"clf__min_samples_leaf\": [i+1 for i in range(10)],\n",
    "                   \"vect__ngram_range\": [(1, 1), (1, 2), (1,3), (1,4)],\n",
    "                   'vect__max_features': [i+10 for i in range(10)],\n",
    "                    \"tfidf__use_idf\": (True, False)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = Pipeline([('vect', CountVectorizer()), \n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', RandomForestClassifier())])\n",
    "\n",
    "randSearch = RandomizedSearchCV(estimator = rf_clf, \n",
    "                   param_distributions = rfParams,\n",
    "                   n_iter = 100, cv = 3, verbose=2,\n",
    "                   random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "randSearch.fit(trainTxt, trTarg)\n",
    "\n",
    "best_random = randSearch.best_estimator_\n",
   
    "\n",
    "_ = best_random.fit(trainTxt, trTarg)\n",
    "\n",
    "predicted = best_random.predict(testTxt)\n",
    "\n",
    "\n",
    "print(randSearch.best_score_)\n",
    "print(randSearch.best_params_)\n",
    "print()\n",
    "print()\n",
    "\n",
    "print()\n",
    "print()\n",
    "print(np.mean(predicted == tsTarg))\n",
    "print()\n",
    "print(\"classification report\")\n",
    "print(metrics.classification_report(tsTarg, predicted))\n",
    "print()\n",
    "print(\"confusion mtx\")\n",
    "print(metrics.confusion_matrix(tsTarg, predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   23.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.695749440716\n",
      "{'vect__ngram_range': (1, 4), 'vect__max_features': 15, 'tfidf__use_idf': True, 'clf__alpha': 0.40000000000000002}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.673333333333\n",
      "\n",
      "classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.68      0.97      0.80        99\n",
      "        1.0       0.62      0.10      0.17        51\n",
      "\n",
      "avg / total       0.66      0.67      0.58       150\n",
      "\n",
      "\n",
      "confusion mtx\n",
      "[[96  3]\n",
      " [46  5]]\n"
     ]
    }
   ],
   "source": [
    "mnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2), (1,3), (1,4)],\n",
    "            'vect__max_features': [i+15 for i in range(10)],\n",
    "            \"tfidf__use_idf\": (True, False),\n",
    "            \"clf__alpha\": np.arange(0, 1.1, 0.1)}\n",
    "\n",
    "mnb_clf = Pipeline([('vect', CountVectorizer()), \n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB())])\n",
    "\n",
    "randSearch = RandomizedSearchCV(estimator = mnb_clf, \n",
    "                   param_distributions = mnbParams,\n",
    "                   n_iter = 100, cv = 3, verbose=2,\n",
    "                   random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "randSearch.fit(trainTxt, trTarg)\n",
    "\n",
    "best_random = randSearch.best_estimator_\n",
    "# random_accuracy = evaluate(best_random, \n",
    "#                            testTxt,\n",
    "#                            tsTarg)\n",
    "\n",
    "_ = best_random.fit(trainTxt, trTarg)\n",
    "\n",
    "predicted = best_random.predict(testTxt)\n",
    "\n",
    "\n",
    "print(randSearch.best_score_)\n",
    "print(randSearch.best_params_)\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print(np.mean(predicted == tsTarg))\n",
    "print()\n",
    "print(\"classification report\")\n",
    "print(metrics.classification_report(tsTarg, predicted))\n",
    "print()\n",
    "print(\"confusion mtx\")\n",
    "print(metrics.confusion_matrix(tsTarg, predicted))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   22.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.68903803132\n",
      "{'vect__ngram_range': (1, 4), 'vect__max_features': 18, 'tfidf__use_idf': False, 'clf__alpha': 0.70000000000000007}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.686666666667\n",
      "\n",
      "classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.78      0.73      0.75        99\n",
      "        1.0       0.53      0.61      0.57        51\n",
      "\n",
      "avg / total       0.70      0.69      0.69       150\n",
      "\n",
      "\n",
      "confusion mtx\n",
      "[[72 27]\n",
      " [20 31]]\n"
     ]
    }
   ],
   "source": [
    "bnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2), (1,3), (1,4)],\n",
    "            'vect__max_features': [i+15 for i in range(10)],\n",
    "            \"tfidf__use_idf\": (True, False),\n",
    "            \"clf__alpha\": np.arange(0, 1.1, 0.1)}\n",
    "\n",
    "bnb_clf = Pipeline([('vect', CountVectorizer()), \n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', BernoulliNB())])\n",
    "\n",
    "randSearch = RandomizedSearchCV(estimator = bnb_clf, \n",
    "                   param_distributions = mnbParams,\n",
    "                   n_iter = 100, cv = 3, verbose=2,\n",
    "                   random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "randSearch.fit(trainTxt, trTarg)\n",
    "\n",
    "best_random = randSearch.best_estimator_\n",
   
    "\n",
    "_ = best_random.fit(trainTxt, trTarg)\n",
    "\n",
    "predicted = best_random.predict(testTxt)\n",
    "\n",
    "\n",
    "print(randSearch.best_score_)\n",
    "print(randSearch.best_params_)\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print(np.mean(predicted == tsTarg))\n",
    "print()\n",
    "print(\"classification report\")\n",
    "print(metrics.classification_report(tsTarg, predicted))\n",
    "print()\n",
    "print(\"confusion mtx\")\n",
    "print(metrics.confusion_matrix(tsTarg, predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 70 candidates, totalling 210 fits\n"
     ]
    },
    {
     "ename": "JoblibTypeError",
     "evalue": "JoblibTypeError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x000000E5F37F0C90, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\A...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x000000E5F37F0C90, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\A...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...int(metrics.confusion_matrix(tsTarg, predicted))\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 10, 31, 3, 19, 44, 458506, tzinfo=tzutc()), 'msg_id': '8B1CF3289B42457C8802C240F2E03DCA', 'msg_type': 'execute_request', 'session': '37C2346CBD894BB6AFC06AF5C68B8DE2', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '8B1CF3289B42457C8802C240F2E03DCA', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'37C2346CBD894BB6AFC06AF5C68B8DE2']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...int(metrics.confusion_matrix(tsTarg, predicted))\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 10, 31, 3, 19, 44, 458506, tzinfo=tzutc()), 'msg_id': '8B1CF3289B42457C8802C240F2E03DCA', 'msg_type': 'execute_request', 'session': '37C2346CBD894BB6AFC06AF5C68B8DE2', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '8B1CF3289B42457C8802C240F2E03DCA', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'37C2346CBD894BB6AFC06AF5C68B8DE2'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...int(metrics.confusion_matrix(tsTarg, predicted))\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 10, 31, 3, 19, 44, 458506, tzinfo=tzutc()), 'msg_id': '8B1CF3289B42457C8802C240F2E03DCA', 'msg_type': 'execute_request', 'session': '37C2346CBD894BB6AFC06AF5C68B8DE2', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '8B1CF3289B42457C8802C240F2E03DCA', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...int(metrics.confusion_matrix(tsTarg, predicted))\\n', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...int(metrics.confusion_matrix(tsTarg, predicted))\\n'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...int(metrics.confusion_matrix(tsTarg, predicted))\\n',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...int(metrics.confusion_matrix(tsTarg, predicted))\\n',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...int(metrics.confusion_matrix(tsTarg, predicted))\\n', store_history=True, silent=False, shell_futures=True)\n   2693                 self.displayhook.exec_result = result\n   2694 \n   2695                 # Execute the user code\n   2696                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2697                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2698                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2699                 \n   2700                 self.last_execution_succeeded = not has_raised\n   2701 \n   2702                 # Reset this so later displayed values do not modify the\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>], cell_name='<ipython-input-19-bd8e5ab9a579>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at e5802ca898, execution..._before_exec=None error_in_exec=None result=None>)\n   2797 \n   2798         try:\n   2799             for i, node in enumerate(to_run_exec):\n   2800                 mod = ast.Module([node])\n   2801                 code = compiler(mod, cell_name, \"exec\")\n-> 2802                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x000000E5FF99E810, file \"<ipython-input-19-bd8e5ab9a579>\", line 15>\n        result = <ExecutionResult object at e5802ca898, execution..._before_exec=None error_in_exec=None result=None>\n   2803                     return True\n   2804 \n   2805             for i, node in enumerate(to_run_interactive):\n   2806                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000000E5FF99E810, file \"<ipython-input-19-bd8e5ab9a579>\", line 15>, result=<ExecutionResult object at e5802ca898, execution..._before_exec=None error_in_exec=None result=None>)\n   2857         outflag = True  # happens in more places, so it's easier as default\n   2858         try:\n   2859             try:\n   2860                 self.hooks.pre_run_code_hook()\n   2861                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2862                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x000000E5FF99E810, file \"<ipython-input-19-bd8e5ab9a579>\", line 15>\n        self.user_global_ns = {'BernoulliNB': <class 'sklearn.naive_bayes.BernoulliNB'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'FreqDist': <class 'nltk.probability.FreqDist'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import nltk\\nfrom nltk.corpus import stopwords\\nfr... import BernoulliNB\\n\\n\\nfrom sklearn import metrics', 'def getData():\\n    \\n    data = pd.read_csv(\"Book...s titles \"Unnamed\"\\n    \\n    return data\\n    \\n    ', 'def addPOS(df, ps):\\n    \\n    taggedTxt = []\\n    ...es(taggedTxt, index = df.index)\\n    return column', 'def tag_txt(txt, ps):\\n    #is passed a string of...taggedLst.append(word)\\n    \\n\\n    return taggedLst', 'def getFeatsCART(series):\\n    \\n    valList = []\\n...es(valList)\\n    \\n    return stemTxtCol\\n\\n    \\n    ', '\\nreviews = getData()\\nps = PorterStemmer()', 'reviews.loc[:, \"pos_stem\"] = addPOS(reviews.loc[...processed, tagged words as a new column of the df', 'reviews.loc[:, \"stemTxtCol\"] = getFeatsCART(reviews.loc[:, \\'pos_stem\\'])', 'txtList = [reviews.loc[:, \"stemTxtCol\"].iloc[i] ...rgArr[:piv]\\ntsTarg = targArr[piv:]\\n        \\n\\n    ', 'mnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2..._)\\nprint(randSearch.best_params_)\\nprint()\\nprint()', 'mnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'bnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'import nltk\\nfrom nltk.corpus import stopwords\\nfr...oulliNB, GaussianNB\\n\\n\\nfrom sklearn import metrics', 'def getData():\\n    \\n    data = pd.read_csv(\"Book...s titles \"Unnamed\"\\n    \\n    return data\\n    \\n    ', 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))'], 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'Out': {}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, ...}\n        self.user_ns = {'BernoulliNB': <class 'sklearn.naive_bayes.BernoulliNB'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'FreqDist': <class 'nltk.probability.FreqDist'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import nltk\\nfrom nltk.corpus import stopwords\\nfr... import BernoulliNB\\n\\n\\nfrom sklearn import metrics', 'def getData():\\n    \\n    data = pd.read_csv(\"Book...s titles \"Unnamed\"\\n    \\n    return data\\n    \\n    ', 'def addPOS(df, ps):\\n    \\n    taggedTxt = []\\n    ...es(taggedTxt, index = df.index)\\n    return column', 'def tag_txt(txt, ps):\\n    #is passed a string of...taggedLst.append(word)\\n    \\n\\n    return taggedLst', 'def getFeatsCART(series):\\n    \\n    valList = []\\n...es(valList)\\n    \\n    return stemTxtCol\\n\\n    \\n    ', '\\nreviews = getData()\\nps = PorterStemmer()', 'reviews.loc[:, \"pos_stem\"] = addPOS(reviews.loc[...processed, tagged words as a new column of the df', 'reviews.loc[:, \"stemTxtCol\"] = getFeatsCART(reviews.loc[:, \\'pos_stem\\'])', 'txtList = [reviews.loc[:, \"stemTxtCol\"].iloc[i] ...rgArr[:piv]\\ntsTarg = targArr[piv:]\\n        \\n\\n    ', 'mnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2..._)\\nprint(randSearch.best_params_)\\nprint()\\nprint()', 'mnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'bnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'import nltk\\nfrom nltk.corpus import stopwords\\nfr...oulliNB, GaussianNB\\n\\n\\nfrom sklearn import metrics', 'def getData():\\n    \\n    data = pd.read_csv(\"Book...s titles \"Unnamed\"\\n    \\n    return data\\n    \\n    ', 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))'], 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'Out': {}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, ...}\n   2863             finally:\n   2864                 # Reset our crash handler in place\n   2865                 sys.excepthook = old_excepthook\n   2866         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\Aubrey\\Documents\\BookReviews\\<ipython-input-19-bd8e5ab9a579> in <module>()\n     10 randSearch = RandomizedSearchCV(estimator = gnb_clf, \n     11                    param_distributions = gnbParams,\n     12                    n_iter = 70, cv = 3, verbose=2,\n     13                    random_state=42, n_jobs = -1)\n     14 # Fit the random search model\n---> 15 randSearch.fit(trainTxt, trTarg)\n     16 \n     17 best_random = randSearch.best_estimator_\n     18 # random_accuracy = evaluate(best_random, \n     19 #                            testTxt,\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self=RandomizedSearchCV(cv=3, error_score='raise',\n  ...return_train_score=True, scoring=None, verbose=2), X=['noth read till 60 put sinc kept get wors oh well ', 'read 80 page book bore ', \"strongli dislik book clich fill stori 've encoun... bit silli 's definit least trope fill part book \", \"second chanc read still dnf could n't continu 'm...i 'll stand movi book n't interest well ... page \", 'basic list refer poorli written fantasi nerd stu...s tacki bland like big bang theori probabl enjoy ', \"3.5 star found stori compel time label emot colo...i come term 's nice littl romanc brew stori well \", 'horribl soap opera void anyth alaska plot conclus reveal first chapter ', 'idea mani peopl gave book five star quick read c...like wast time reason finish book book club pick ', \"good surviv stori quit page-grip work boy bengal... ride extrem difficult condit 's worth read book \", 'dnf hate book read school bye ', 'slow bore far ', 'didn\\x92t like kept wait someth happen writer spent...ess want book end doesn\\x92t amazon give money back ', 'chapter 2 done book garbag ', \"n't like fact everyon 's point veiw kinda lost interest like book jump person person \", 'well go break ', 'pc suck jfc absolut sick death pc regim one oppr...h b far better literatur 21st centuri propaganda ', \"tri read finish read ca n't seem finish \", 'novel moment mainli descript alaska time letter ...hin due much predict novel progress banal surfac ', 'difficult book finish well written read first quarter rent movi finish may get book tape well ', 'audio version book dnf concept realli good listen half got bit gruesom shame want find happen ', ...], y=array([ 1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  ...,  0.,  1.,  0.,\n        0.,  0.,  0.,  0.,  0.]), groups=None, **fit_params={})\n    633                                   return_train_score=self.return_train_score,\n    634                                   return_n_test_samples=True,\n    635                                   return_times=True, return_parameters=False,\n    636                                   error_score=self.error_score)\n    637           for parameters, (train, test) in product(candidate_params,\n--> 638                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=3, random_state=None, shuffle=False)>\n        X = ['noth read till 60 put sinc kept get wors oh well ', 'read 80 page book bore ', \"strongli dislik book clich fill stori 've encoun... bit silli 's definit least trope fill part book \", \"second chanc read still dnf could n't continu 'm...i 'll stand movi book n't interest well ... page \", 'basic list refer poorli written fantasi nerd stu...s tacki bland like big bang theori probabl enjoy ', \"3.5 star found stori compel time label emot colo...i come term 's nice littl romanc brew stori well \", 'horribl soap opera void anyth alaska plot conclus reveal first chapter ', 'idea mani peopl gave book five star quick read c...like wast time reason finish book book club pick ', \"good surviv stori quit page-grip work boy bengal... ride extrem difficult condit 's worth read book \", 'dnf hate book read school bye ', 'slow bore far ', 'didn\\x92t like kept wait someth happen writer spent...ess want book end doesn\\x92t amazon give money back ', 'chapter 2 done book garbag ', \"n't like fact everyon 's point veiw kinda lost interest like book jump person person \", 'well go break ', 'pc suck jfc absolut sick death pc regim one oppr...h b far better literatur 21st centuri propaganda ', \"tri read finish read ca n't seem finish \", 'novel moment mainli descript alaska time letter ...hin due much predict novel progress banal surfac ', 'difficult book finish well written read first quarter rent movi finish may get book tape well ', 'audio version book dnf concept realli good listen half got bit gruesom shame want find happen ', ...]\n        y = array([ 1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  ...,  0.,  1.,  0.,\n        0.,  0.,  0.,  0.,  0.])\n        groups = None\n    639 \n    640         # if one choose to see train score, \"out\" will contain train score info\n    641         if self.return_train_score:\n    642             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nTypeError                                          Tue Oct 30 22:19:45 2018\nPID: 5928                Python 3.6.2: C:\\Users\\Aubrey\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('vect', Count...se_idf=True)), ('clf', GaussianNB(priors=None))]), ['noth read till 60 put sinc kept get wors oh well ', 'read 80 page book bore ', \"strongli dislik book clich fill stori 've encoun... bit silli 's definit least trope fill part book \", \"second chanc read still dnf could n't continu 'm...i 'll stand movi book n't interest well ... page \", 'basic list refer poorli written fantasi nerd stu...s tacki bland like big bang theori probabl enjoy ', \"3.5 star found stori compel time label emot colo...i come term 's nice littl romanc brew stori well \", 'horribl soap opera void anyth alaska plot conclus reveal first chapter ', 'idea mani peopl gave book five star quick read c...like wast time reason finish book book club pick ', \"good surviv stori quit page-grip work boy bengal... ride extrem difficult condit 's worth read book \", 'dnf hate book read school bye ', 'slow bore far ', 'didn\\x92t like kept wait someth happen writer spent...ess want book end doesn\\x92t amazon give money back ', 'chapter 2 done book garbag ', \"n't like fact everyon 's point veiw kinda lost interest like book jump person person \", 'well go break ', 'pc suck jfc absolut sick death pc regim one oppr...h b far better literatur 21st centuri propaganda ', \"tri read finish read ca n't seem finish \", 'novel moment mainli descript alaska time letter ...hin due much predict novel progress banal surfac ', 'difficult book finish well written read first quarter rent movi finish may get book tape well ', 'audio version book dnf concept realli good listen half got bit gruesom shame want find happen ', ...], array([ 1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  ...,  0.,  1.,  0.,\n        0.,  0.,  0.,  0.,  0.]), {'score': <function _passthrough_scorer>}, array([146, 148, 149, 150, 153, 154, 155, 156, 1...37, 438, 439, 440, 441, 442, 443, 444, 445, 446]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 141, 142,\n       143, 144, 145, 147, 151, 152]), 2, {'tfidf__use_idf': True, 'vect__max_features': 22, 'vect__ngram_range': (1, 3)}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('vect', Count...se_idf=True)), ('clf', GaussianNB(priors=None))]), ['noth read till 60 put sinc kept get wors oh well ', 'read 80 page book bore ', \"strongli dislik book clich fill stori 've encoun... bit silli 's definit least trope fill part book \", \"second chanc read still dnf could n't continu 'm...i 'll stand movi book n't interest well ... page \", 'basic list refer poorli written fantasi nerd stu...s tacki bland like big bang theori probabl enjoy ', \"3.5 star found stori compel time label emot colo...i come term 's nice littl romanc brew stori well \", 'horribl soap opera void anyth alaska plot conclus reveal first chapter ', 'idea mani peopl gave book five star quick read c...like wast time reason finish book book club pick ', \"good surviv stori quit page-grip work boy bengal... ride extrem difficult condit 's worth read book \", 'dnf hate book read school bye ', 'slow bore far ', 'didn\\x92t like kept wait someth happen writer spent...ess want book end doesn\\x92t amazon give money back ', 'chapter 2 done book garbag ', \"n't like fact everyon 's point veiw kinda lost interest like book jump person person \", 'well go break ', 'pc suck jfc absolut sick death pc regim one oppr...h b far better literatur 21st centuri propaganda ', \"tri read finish read ca n't seem finish \", 'novel moment mainli descript alaska time letter ...hin due much predict novel progress banal surfac ', 'difficult book finish well written read first quarter rent movi finish may get book tape well ', 'audio version book dnf concept realli good listen half got bit gruesom shame want find happen ', ...], array([ 1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  ...,  0.,  1.,  0.,\n        0.,  0.,  0.,  0.,  0.]), {'score': <function _passthrough_scorer>}, array([146, 148, 149, 150, 153, 154, 155, 156, 1...37, 438, 439, 440, 441, 442, 443, 444, 445, 446]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 141, 142,\n       143, 144, 145, 147, 151, 152]), 2, {'tfidf__use_idf': True, 'vect__max_features': 22, 'vect__ngram_range': (1, 3)})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('vect', Count...se_idf=True)), ('clf', GaussianNB(priors=None))]), X=['noth read till 60 put sinc kept get wors oh well ', 'read 80 page book bore ', \"strongli dislik book clich fill stori 've encoun... bit silli 's definit least trope fill part book \", \"second chanc read still dnf could n't continu 'm...i 'll stand movi book n't interest well ... page \", 'basic list refer poorli written fantasi nerd stu...s tacki bland like big bang theori probabl enjoy ', \"3.5 star found stori compel time label emot colo...i come term 's nice littl romanc brew stori well \", 'horribl soap opera void anyth alaska plot conclus reveal first chapter ', 'idea mani peopl gave book five star quick read c...like wast time reason finish book book club pick ', \"good surviv stori quit page-grip work boy bengal... ride extrem difficult condit 's worth read book \", 'dnf hate book read school bye ', 'slow bore far ', 'didn\\x92t like kept wait someth happen writer spent...ess want book end doesn\\x92t amazon give money back ', 'chapter 2 done book garbag ', \"n't like fact everyon 's point veiw kinda lost interest like book jump person person \", 'well go break ', 'pc suck jfc absolut sick death pc regim one oppr...h b far better literatur 21st centuri propaganda ', \"tri read finish read ca n't seem finish \", 'novel moment mainli descript alaska time letter ...hin due much predict novel progress banal surfac ', 'difficult book finish well written read first quarter rent movi finish may get book tape well ', 'audio version book dnf concept realli good listen half got bit gruesom shame want find happen ', ...], y=array([ 1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  ...,  0.,  1.,  0.,\n        0.,  0.,  0.,  0.,  0.]), scorer={'score': <function _passthrough_scorer>}, train=array([146, 148, 149, 150, 153, 154, 155, 156, 1...37, 438, 439, 440, 441, 442, 443, 444, 445, 446]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 141, 142,\n       143, 144, 145, 147, 151, 152]), verbose=2, parameters={'tfidf__use_idf': True, 'vect__max_features': 22, 'vect__ngram_range': (1, 3)}, fit_params={}, return_train_score=True, return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    432 \n    433     try:\n    434         if y_train is None:\n    435             estimator.fit(X_train, **fit_params)\n    436         else:\n--> 437             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...e_idf=True)), ('clf', GaussianNB(priors=None))])>\n        X_train = [\"mini review dnf x2 book circul gr sinc end 2017....at\\x92 overal realli didn\\x92t like book n't recommend \", \"could n't finish \", \"melodramat improb n't finish \", \"could n't get past page 64. flat bore n't like write style \", \"wow..al say brilliant ca n't wait next one may n...seri know find gem read book one sit forgo sleep \", 'finish book put read coupl chapter thought mayb ...ory- none well develop overal found stori bizarr ', 'excel book great studi frailti strength human be...el reader least case would highli recommend book ', \"talent writer hollywood love 3 star sound like p...i would case like would n't left gum-sho partner \", \"n't throw mani book away ... .but one went trash ... depress gave ... 's read \", 'ugh ... ..could finish ', \"50 novel main charact explain minutia random 80 trivia ridicul sad finish 20 book could n't go \", 'love celest ng\\x92 first book everyth never told lo...pt appear end unbeliev izzi one teen age charact ', 'littl fire fast easi read kept attent 3/4 book k... even seen nake man revel hard take book serious ', \"n't finish meander stori \", 'love book holden caulfield told point view made ...hospit end book hope feel thing would get better ', \"probabl one depress book 've read ... yet see ra...t said hit home run book long 's 'fiction reader \", \"crazi disgust crazi disturb ca n't even explain ...ca thriller categori 'll happili put vote toward \", 'antihero ye icon teenag rebellion mayb icon futu...ayb good idea shove throat eighth grader probabl ', \"book religi could n't even finish almost alway finish book \", 'couldn\\x92t get book much hype blah realli want like ', ...]\n        y_train = array([ 1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  ...0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.])\n        fit_params = {}\n    438 \n    439     except Exception as e:\n    440         # Note fit time as time until error\n    441         fit_time = time.time() - start_time\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('vect', Count...se_idf=True)), ('clf', GaussianNB(priors=None))]), X=[\"mini review dnf x2 book circul gr sinc end 2017....at\\x92 overal realli didn\\x92t like book n't recommend \", \"could n't finish \", \"melodramat improb n't finish \", \"could n't get past page 64. flat bore n't like write style \", \"wow..al say brilliant ca n't wait next one may n...seri know find gem read book one sit forgo sleep \", 'finish book put read coupl chapter thought mayb ...ory- none well develop overal found stori bizarr ', 'excel book great studi frailti strength human be...el reader least case would highli recommend book ', \"talent writer hollywood love 3 star sound like p...i would case like would n't left gum-sho partner \", \"n't throw mani book away ... .but one went trash ... depress gave ... 's read \", 'ugh ... ..could finish ', \"50 novel main charact explain minutia random 80 trivia ridicul sad finish 20 book could n't go \", 'love celest ng\\x92 first book everyth never told lo...pt appear end unbeliev izzi one teen age charact ', 'littl fire fast easi read kept attent 3/4 book k... even seen nake man revel hard take book serious ', \"n't finish meander stori \", 'love book holden caulfield told point view made ...hospit end book hope feel thing would get better ', \"probabl one depress book 've read ... yet see ra...t said hit home run book long 's 'fiction reader \", \"crazi disgust crazi disturb ca n't even explain ...ca thriller categori 'll happili put vote toward \", 'antihero ye icon teenag rebellion mayb icon futu...ayb good idea shove throat eighth grader probabl ', \"book religi could n't even finish almost alway finish book \", 'couldn\\x92t get book much hype blah realli want like ', ...], y=array([ 1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  ...0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.]), **fit_params={})\n    254         self : Pipeline\n    255             This estimator\n    256         \"\"\"\n    257         Xt, fit_params = self._fit(X, y, **fit_params)\n    258         if self._final_estimator is not None:\n--> 259             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method GaussianNB.fit of GaussianNB(priors=None)>\n        Xt = <298x22 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>\n        y = array([ 1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  ...0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.])\n        fit_params = {}\n    260         return self\n    261 \n    262     def fit_transform(self, X, y=None, **fit_params):\n    263         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py in fit(self=GaussianNB(priors=None), X=<298x22 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>, y=array([ 1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  ...0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.]), sample_weight=None)\n    178         Returns\n    179         -------\n    180         self : object\n    181             Returns self.\n    182         \"\"\"\n--> 183         X, y = check_X_y(X, y)\n        X = <298x22 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>\n        y = array([ 1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  ...0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.])\n    184         return self._partial_fit(X, y, np.unique(y), _refit=True,\n    185                                  sample_weight=sample_weight)\n    186 \n    187     @staticmethod\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py in check_X_y(X=<298x22 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>, y=array([ 1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  ...0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.]), accept_sparse=False, dtype='numeric', order=None, copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, multi_output=False, ensure_min_samples=1, ensure_min_features=1, y_numeric=False, warn_on_dtype=False, estimator=None)\n    537     y_converted : object\n    538         The converted and validated y.\n    539     \"\"\"\n    540     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n    541                     ensure_2d, allow_nd, ensure_min_samples,\n--> 542                     ensure_min_features, warn_on_dtype, estimator)\n        ensure_min_features = 1\n        warn_on_dtype = False\n        estimator = None\n    543     if multi_output:\n    544         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n    545                         dtype=None)\n    546     else:\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py in check_array(array=<298x22 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>, accept_sparse=False, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)\n    395         estimator_name = \"Estimator\"\n    396     context = \" by %s\" % estimator_name if estimator is not None else \"\"\n    397 \n    398     if sp.issparse(array):\n    399         array = _ensure_sparse_format(array, accept_sparse, dtype, copy,\n--> 400                                       force_all_finite)\n        force_all_finite = True\n    401     else:\n    402         array = np.array(array, dtype=dtype, order=order, copy=copy)\n    403 \n    404         if ensure_2d:\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py in _ensure_sparse_format(spmatrix=<298x22 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>, accept_sparse=False, dtype=dtype('float64'), copy=False, force_all_finite=True)\n    239 \n    240     if isinstance(accept_sparse, six.string_types):\n    241         accept_sparse = [accept_sparse]\n    242 \n    243     if accept_sparse is False:\n--> 244         raise TypeError('A sparse matrix was passed, but dense '\n    245                         'data is required. Use X.toarray() to '\n    246                         'convert to a dense numpy array.')\n    247     elif isinstance(accept_sparse, (list, tuple)):\n    248         if len(accept_sparse) == 0:\n\nTypeError: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 437, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 259, in fit\n    self._final_estimator.fit(Xt, y, **fit_params)\n  File \"C:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 183, in fit\n    X, y = check_X_y(X, y)\n  File \"C:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 542, in check_X_y\n    ensure_min_features, warn_on_dtype, estimator)\n  File \"C:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 400, in check_array\n    force_all_finite)\n  File \"C:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 244, in _ensure_sparse_format\n    raise TypeError('A sparse matrix was passed, but dense '\nTypeError: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\Aubrey\\Anaconda3\\lib\\multiprocessing\\pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"C:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nTypeError                                          Tue Oct 30 22:19:45 2018\nPID: 5928                Python 3.6.2: C:\\Users\\Aubrey\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('vect', Count...se_idf=True)), ('clf', GaussianNB(priors=None))]), ['noth read till 60 put sinc kept get wors oh well ', 'read 80 page book bore ', \"strongli dislik book clich fill stori 've encoun... bit silli 's definit least trope fill part book \", \"second chanc read still dnf could n't continu 'm...i 'll stand movi book n't interest well ... page \", 'basic list refer poorli written fantasi nerd stu...s tacki bland like big bang theori probabl enjoy ', \"3.5 star found stori compel time label emot colo...i come term 's nice littl romanc brew stori well \", 'horribl soap opera void anyth alaska plot conclus reveal first chapter ', 'idea mani peopl gave book five star quick read c...like wast time reason finish book book club pick ', \"good surviv stori quit page-grip work boy bengal... ride extrem difficult condit 's worth read book \", 'dnf hate book read school bye ', 'slow bore far ', 'didn\\x92t like kept wait someth happen writer spent...ess want book end doesn\\x92t amazon give money back ', 'chapter 2 done book garbag ', \"n't like fact everyon 's point veiw kinda lost interest like book jump person person \", 'well go break ', 'pc suck jfc absolut sick death pc regim one oppr...h b far better literatur 21st centuri propaganda ', \"tri read finish read ca n't seem finish \", 'novel moment mainli descript alaska time letter ...hin due much predict novel progress banal surfac ', 'difficult book finish well written read first quarter rent movi finish may get book tape well ', 'audio version book dnf concept realli good listen half got bit gruesom shame want find happen ', ...], array([ 1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  ...,  0.,  1.,  0.,\n        0.,  0.,  0.,  0.,  0.]), {'score': <function _passthrough_scorer>}, array([146, 148, 149, 150, 153, 154, 155, 156, 1...37, 438, 439, 440, 441, 442, 443, 444, 445, 446]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 141, 142,\n       143, 144, 145, 147, 151, 152]), 2, {'tfidf__use_idf': True, 'vect__max_features': 22, 'vect__ngram_range': (1, 3)}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('vect', Count...se_idf=True)), ('clf', GaussianNB(priors=None))]), ['noth read till 60 put sinc kept get wors oh well ', 'read 80 page book bore ', \"strongli dislik book clich fill stori 've encoun... bit silli 's definit least trope fill part book \", \"second chanc read still dnf could n't continu 'm...i 'll stand movi book n't interest well ... page \", 'basic list refer poorli written fantasi nerd stu...s tacki bland like big bang theori probabl enjoy ', \"3.5 star found stori compel time label emot colo...i come term 's nice littl romanc brew stori well \", 'horribl soap opera void anyth alaska plot conclus reveal first chapter ', 'idea mani peopl gave book five star quick read c...like wast time reason finish book book club pick ', \"good surviv stori quit page-grip work boy bengal... ride extrem difficult condit 's worth read book \", 'dnf hate book read school bye ', 'slow bore far ', 'didn\\x92t like kept wait someth happen writer spent...ess want book end doesn\\x92t amazon give money back ', 'chapter 2 done book garbag ', \"n't like fact everyon 's point veiw kinda lost interest like book jump person person \", 'well go break ', 'pc suck jfc absolut sick death pc regim one oppr...h b far better literatur 21st centuri propaganda ', \"tri read finish read ca n't seem finish \", 'novel moment mainli descript alaska time letter ...hin due much predict novel progress banal surfac ', 'difficult book finish well written read first quarter rent movi finish may get book tape well ', 'audio version book dnf concept realli good listen half got bit gruesom shame want find happen ', ...], array([ 1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  ...,  0.,  1.,  0.,\n        0.,  0.,  0.,  0.,  0.]), {'score': <function _passthrough_scorer>}, array([146, 148, 149, 150, 153, 154, 155, 156, 1...37, 438, 439, 440, 441, 442, 443, 444, 445, 446]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 141, 142,\n       143, 144, 145, 147, 151, 152]), 2, {'tfidf__use_idf': True, 'vect__max_features': 22, 'vect__ngram_range': (1, 3)})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('vect', Count...se_idf=True)), ('clf', GaussianNB(priors=None))]), X=['noth read till 60 put sinc kept get wors oh well ', 'read 80 page book bore ', \"strongli dislik book clich fill stori 've encoun... bit silli 's definit least trope fill part book \", \"second chanc read still dnf could n't continu 'm...i 'll stand movi book n't interest well ... page \", 'basic list refer poorli written fantasi nerd stu...s tacki bland like big bang theori probabl enjoy ', \"3.5 star found stori compel time label emot colo...i come term 's nice littl romanc brew stori well \", 'horribl soap opera void anyth alaska plot conclus reveal first chapter ', 'idea mani peopl gave book five star quick read c...like wast time reason finish book book club pick ', \"good surviv stori quit page-grip work boy bengal... ride extrem difficult condit 's worth read book \", 'dnf hate book read school bye ', 'slow bore far ', 'didn\\x92t like kept wait someth happen writer spent...ess want book end doesn\\x92t amazon give money back ', 'chapter 2 done book garbag ', \"n't like fact everyon 's point veiw kinda lost interest like book jump person person \", 'well go break ', 'pc suck jfc absolut sick death pc regim one oppr...h b far better literatur 21st centuri propaganda ', \"tri read finish read ca n't seem finish \", 'novel moment mainli descript alaska time letter ...hin due much predict novel progress banal surfac ', 'difficult book finish well written read first quarter rent movi finish may get book tape well ', 'audio version book dnf concept realli good listen half got bit gruesom shame want find happen ', ...], y=array([ 1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  ...,  0.,  1.,  0.,\n        0.,  0.,  0.,  0.,  0.]), scorer={'score': <function _passthrough_scorer>}, train=array([146, 148, 149, 150, 153, 154, 155, 156, 1...37, 438, 439, 440, 441, 442, 443, 444, 445, 446]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 141, 142,\n       143, 144, 145, 147, 151, 152]), verbose=2, parameters={'tfidf__use_idf': True, 'vect__max_features': 22, 'vect__ngram_range': (1, 3)}, fit_params={}, return_train_score=True, return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    432 \n    433     try:\n    434         if y_train is None:\n    435             estimator.fit(X_train, **fit_params)\n    436         else:\n--> 437             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...e_idf=True)), ('clf', GaussianNB(priors=None))])>\n        X_train = [\"mini review dnf x2 book circul gr sinc end 2017....at\\x92 overal realli didn\\x92t like book n't recommend \", \"could n't finish \", \"melodramat improb n't finish \", \"could n't get past page 64. flat bore n't like write style \", \"wow..al say brilliant ca n't wait next one may n...seri know find gem read book one sit forgo sleep \", 'finish book put read coupl chapter thought mayb ...ory- none well develop overal found stori bizarr ', 'excel book great studi frailti strength human be...el reader least case would highli recommend book ', \"talent writer hollywood love 3 star sound like p...i would case like would n't left gum-sho partner \", \"n't throw mani book away ... .but one went trash ... depress gave ... 's read \", 'ugh ... ..could finish ', \"50 novel main charact explain minutia random 80 trivia ridicul sad finish 20 book could n't go \", 'love celest ng\\x92 first book everyth never told lo...pt appear end unbeliev izzi one teen age charact ', 'littl fire fast easi read kept attent 3/4 book k... even seen nake man revel hard take book serious ', \"n't finish meander stori \", 'love book holden caulfield told point view made ...hospit end book hope feel thing would get better ', \"probabl one depress book 've read ... yet see ra...t said hit home run book long 's 'fiction reader \", \"crazi disgust crazi disturb ca n't even explain ...ca thriller categori 'll happili put vote toward \", 'antihero ye icon teenag rebellion mayb icon futu...ayb good idea shove throat eighth grader probabl ', \"book religi could n't even finish almost alway finish book \", 'couldn\\x92t get book much hype blah realli want like ', ...]\n        y_train = array([ 1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  ...0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.])\n        fit_params = {}\n    438 \n    439     except Exception as e:\n    440         # Note fit time as time until error\n    441         fit_time = time.time() - start_time\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('vect', Count...se_idf=True)), ('clf', GaussianNB(priors=None))]), X=[\"mini review dnf x2 book circul gr sinc end 2017....at\\x92 overal realli didn\\x92t like book n't recommend \", \"could n't finish \", \"melodramat improb n't finish \", \"could n't get past page 64. flat bore n't like write style \", \"wow..al say brilliant ca n't wait next one may n...seri know find gem read book one sit forgo sleep \", 'finish book put read coupl chapter thought mayb ...ory- none well develop overal found stori bizarr ', 'excel book great studi frailti strength human be...el reader least case would highli recommend book ', \"talent writer hollywood love 3 star sound like p...i would case like would n't left gum-sho partner \", \"n't throw mani book away ... .but one went trash ... depress gave ... 's read \", 'ugh ... ..could finish ', \"50 novel main charact explain minutia random 80 trivia ridicul sad finish 20 book could n't go \", 'love celest ng\\x92 first book everyth never told lo...pt appear end unbeliev izzi one teen age charact ', 'littl fire fast easi read kept attent 3/4 book k... even seen nake man revel hard take book serious ', \"n't finish meander stori \", 'love book holden caulfield told point view made ...hospit end book hope feel thing would get better ', \"probabl one depress book 've read ... yet see ra...t said hit home run book long 's 'fiction reader \", \"crazi disgust crazi disturb ca n't even explain ...ca thriller categori 'll happili put vote toward \", 'antihero ye icon teenag rebellion mayb icon futu...ayb good idea shove throat eighth grader probabl ', \"book religi could n't even finish almost alway finish book \", 'couldn\\x92t get book much hype blah realli want like ', ...], y=array([ 1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  ...0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.]), **fit_params={})\n    254         self : Pipeline\n    255             This estimator\n    256         \"\"\"\n    257         Xt, fit_params = self._fit(X, y, **fit_params)\n    258         if self._final_estimator is not None:\n--> 259             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method GaussianNB.fit of GaussianNB(priors=None)>\n        Xt = <298x22 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>\n        y = array([ 1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  ...0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.])\n        fit_params = {}\n    260         return self\n    261 \n    262     def fit_transform(self, X, y=None, **fit_params):\n    263         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py in fit(self=GaussianNB(priors=None), X=<298x22 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>, y=array([ 1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  ...0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.]), sample_weight=None)\n    178         Returns\n    179         -------\n    180         self : object\n    181             Returns self.\n    182         \"\"\"\n--> 183         X, y = check_X_y(X, y)\n        X = <298x22 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>\n        y = array([ 1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  ...0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.])\n    184         return self._partial_fit(X, y, np.unique(y), _refit=True,\n    185                                  sample_weight=sample_weight)\n    186 \n    187     @staticmethod\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py in check_X_y(X=<298x22 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>, y=array([ 1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  ...0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.]), accept_sparse=False, dtype='numeric', order=None, copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, multi_output=False, ensure_min_samples=1, ensure_min_features=1, y_numeric=False, warn_on_dtype=False, estimator=None)\n    537     y_converted : object\n    538         The converted and validated y.\n    539     \"\"\"\n    540     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n    541                     ensure_2d, allow_nd, ensure_min_samples,\n--> 542                     ensure_min_features, warn_on_dtype, estimator)\n        ensure_min_features = 1\n        warn_on_dtype = False\n        estimator = None\n    543     if multi_output:\n    544         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n    545                         dtype=None)\n    546     else:\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py in check_array(array=<298x22 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>, accept_sparse=False, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)\n    395         estimator_name = \"Estimator\"\n    396     context = \" by %s\" % estimator_name if estimator is not None else \"\"\n    397 \n    398     if sp.issparse(array):\n    399         array = _ensure_sparse_format(array, accept_sparse, dtype, copy,\n--> 400                                       force_all_finite)\n        force_all_finite = True\n    401     else:\n    402         array = np.array(array, dtype=dtype, order=order, copy=copy)\n    403 \n    404         if ensure_2d:\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py in _ensure_sparse_format(spmatrix=<298x22 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>, accept_sparse=False, dtype=dtype('float64'), copy=False, force_all_finite=True)\n    239 \n    240     if isinstance(accept_sparse, six.string_types):\n    241         accept_sparse = [accept_sparse]\n    242 \n    243     if accept_sparse is False:\n--> 244         raise TypeError('A sparse matrix was passed, but dense '\n    245                         'data is required. Use X.toarray() to '\n    246                         'convert to a dense numpy array.')\n    247     elif isinstance(accept_sparse, (list, tuple)):\n    248         if len(accept_sparse) == 0:\n\nTypeError: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nTypeError                                          Tue Oct 30 22:19:45 2018\nPID: 5928                Python 3.6.2: C:\\Users\\Aubrey\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('vect', Count...se_idf=True)), ('clf', GaussianNB(priors=None))]), ['noth read till 60 put sinc kept get wors oh well ', 'read 80 page book bore ', \"strongli dislik book clich fill stori 've encoun... bit silli 's definit least trope fill part book \", \"second chanc read still dnf could n't continu 'm...i 'll stand movi book n't interest well ... page \", 'basic list refer poorli written fantasi nerd stu...s tacki bland like big bang theori probabl enjoy ', \"3.5 star found stori compel time label emot colo...i come term 's nice littl romanc brew stori well \", 'horribl soap opera void anyth alaska plot conclus reveal first chapter ', 'idea mani peopl gave book five star quick read c...like wast time reason finish book book club pick ', \"good surviv stori quit page-grip work boy bengal... ride extrem difficult condit 's worth read book \", 'dnf hate book read school bye ', 'slow bore far ', 'didn\\x92t like kept wait someth happen writer spent...ess want book end doesn\\x92t amazon give money back ', 'chapter 2 done book garbag ', \"n't like fact everyon 's point veiw kinda lost interest like book jump person person \", 'well go break ', 'pc suck jfc absolut sick death pc regim one oppr...h b far better literatur 21st centuri propaganda ', \"tri read finish read ca n't seem finish \", 'novel moment mainli descript alaska time letter ...hin due much predict novel progress banal surfac ', 'difficult book finish well written read first quarter rent movi finish may get book tape well ', 'audio version book dnf concept realli good listen half got bit gruesom shame want find happen ', ...], array([ 1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  ...,  0.,  1.,  0.,\n        0.,  0.,  0.,  0.,  0.]), {'score': <function _passthrough_scorer>}, array([146, 148, 149, 150, 153, 154, 155, 156, 1...37, 438, 439, 440, 441, 442, 443, 444, 445, 446]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 141, 142,\n       143, 144, 145, 147, 151, 152]), 2, {'tfidf__use_idf': True, 'vect__max_features': 22, 'vect__ngram_range': (1, 3)}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('vect', Count...se_idf=True)), ('clf', GaussianNB(priors=None))]), ['noth read till 60 put sinc kept get wors oh well ', 'read 80 page book bore ', \"strongli dislik book clich fill stori 've encoun... bit silli 's definit least trope fill part book \", \"second chanc read still dnf could n't continu 'm...i 'll stand movi book n't interest well ... page \", 'basic list refer poorli written fantasi nerd stu...s tacki bland like big bang theori probabl enjoy ', \"3.5 star found stori compel time label emot colo...i come term 's nice littl romanc brew stori well \", 'horribl soap opera void anyth alaska plot conclus reveal first chapter ', 'idea mani peopl gave book five star quick read c...like wast time reason finish book book club pick ', \"good surviv stori quit page-grip work boy bengal... ride extrem difficult condit 's worth read book \", 'dnf hate book read school bye ', 'slow bore far ', 'didn\\x92t like kept wait someth happen writer spent...ess want book end doesn\\x92t amazon give money back ', 'chapter 2 done book garbag ', \"n't like fact everyon 's point veiw kinda lost interest like book jump person person \", 'well go break ', 'pc suck jfc absolut sick death pc regim one oppr...h b far better literatur 21st centuri propaganda ', \"tri read finish read ca n't seem finish \", 'novel moment mainli descript alaska time letter ...hin due much predict novel progress banal surfac ', 'difficult book finish well written read first quarter rent movi finish may get book tape well ', 'audio version book dnf concept realli good listen half got bit gruesom shame want find happen ', ...], array([ 1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  ...,  0.,  1.,  0.,\n        0.,  0.,  0.,  0.,  0.]), {'score': <function _passthrough_scorer>}, array([146, 148, 149, 150, 153, 154, 155, 156, 1...37, 438, 439, 440, 441, 442, 443, 444, 445, 446]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 141, 142,\n       143, 144, 145, 147, 151, 152]), 2, {'tfidf__use_idf': True, 'vect__max_features': 22, 'vect__ngram_range': (1, 3)})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('vect', Count...se_idf=True)), ('clf', GaussianNB(priors=None))]), X=['noth read till 60 put sinc kept get wors oh well ', 'read 80 page book bore ', \"strongli dislik book clich fill stori 've encoun... bit silli 's definit least trope fill part book \", \"second chanc read still dnf could n't continu 'm...i 'll stand movi book n't interest well ... page \", 'basic list refer poorli written fantasi nerd stu...s tacki bland like big bang theori probabl enjoy ', \"3.5 star found stori compel time label emot colo...i come term 's nice littl romanc brew stori well \", 'horribl soap opera void anyth alaska plot conclus reveal first chapter ', 'idea mani peopl gave book five star quick read c...like wast time reason finish book book club pick ', \"good surviv stori quit page-grip work boy bengal... ride extrem difficult condit 's worth read book \", 'dnf hate book read school bye ', 'slow bore far ', 'didn\\x92t like kept wait someth happen writer spent...ess want book end doesn\\x92t amazon give money back ', 'chapter 2 done book garbag ', \"n't like fact everyon 's point veiw kinda lost interest like book jump person person \", 'well go break ', 'pc suck jfc absolut sick death pc regim one oppr...h b far better literatur 21st centuri propaganda ', \"tri read finish read ca n't seem finish \", 'novel moment mainli descript alaska time letter ...hin due much predict novel progress banal surfac ', 'difficult book finish well written read first quarter rent movi finish may get book tape well ', 'audio version book dnf concept realli good listen half got bit gruesom shame want find happen ', ...], y=array([ 1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  ...,  0.,  1.,  0.,\n        0.,  0.,  0.,  0.,  0.]), scorer={'score': <function _passthrough_scorer>}, train=array([146, 148, 149, 150, 153, 154, 155, 156, 1...37, 438, 439, 440, 441, 442, 443, 444, 445, 446]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 141, 142,\n       143, 144, 145, 147, 151, 152]), verbose=2, parameters={'tfidf__use_idf': True, 'vect__max_features': 22, 'vect__ngram_range': (1, 3)}, fit_params={}, return_train_score=True, return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    432 \n    433     try:\n    434         if y_train is None:\n    435             estimator.fit(X_train, **fit_params)\n    436         else:\n--> 437             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...e_idf=True)), ('clf', GaussianNB(priors=None))])>\n        X_train = [\"mini review dnf x2 book circul gr sinc end 2017....at\\x92 overal realli didn\\x92t like book n't recommend \", \"could n't finish \", \"melodramat improb n't finish \", \"could n't get past page 64. flat bore n't like write style \", \"wow..al say brilliant ca n't wait next one may n...seri know find gem read book one sit forgo sleep \", 'finish book put read coupl chapter thought mayb ...ory- none well develop overal found stori bizarr ', 'excel book great studi frailti strength human be...el reader least case would highli recommend book ', \"talent writer hollywood love 3 star sound like p...i would case like would n't left gum-sho partner \", \"n't throw mani book away ... .but one went trash ... depress gave ... 's read \", 'ugh ... ..could finish ', \"50 novel main charact explain minutia random 80 trivia ridicul sad finish 20 book could n't go \", 'love celest ng\\x92 first book everyth never told lo...pt appear end unbeliev izzi one teen age charact ', 'littl fire fast easi read kept attent 3/4 book k... even seen nake man revel hard take book serious ', \"n't finish meander stori \", 'love book holden caulfield told point view made ...hospit end book hope feel thing would get better ', \"probabl one depress book 've read ... yet see ra...t said hit home run book long 's 'fiction reader \", \"crazi disgust crazi disturb ca n't even explain ...ca thriller categori 'll happili put vote toward \", 'antihero ye icon teenag rebellion mayb icon futu...ayb good idea shove throat eighth grader probabl ', \"book religi could n't even finish almost alway finish book \", 'couldn\\x92t get book much hype blah realli want like ', ...]\n        y_train = array([ 1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  ...0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.])\n        fit_params = {}\n    438 \n    439     except Exception as e:\n    440         # Note fit time as time until error\n    441         fit_time = time.time() - start_time\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('vect', Count...se_idf=True)), ('clf', GaussianNB(priors=None))]), X=[\"mini review dnf x2 book circul gr sinc end 2017....at\\x92 overal realli didn\\x92t like book n't recommend \", \"could n't finish \", \"melodramat improb n't finish \", \"could n't get past page 64. flat bore n't like write style \", \"wow..al say brilliant ca n't wait next one may n...seri know find gem read book one sit forgo sleep \", 'finish book put read coupl chapter thought mayb ...ory- none well develop overal found stori bizarr ', 'excel book great studi frailti strength human be...el reader least case would highli recommend book ', \"talent writer hollywood love 3 star sound like p...i would case like would n't left gum-sho partner \", \"n't throw mani book away ... .but one went trash ... depress gave ... 's read \", 'ugh ... ..could finish ', \"50 novel main charact explain minutia random 80 trivia ridicul sad finish 20 book could n't go \", 'love celest ng\\x92 first book everyth never told lo...pt appear end unbeliev izzi one teen age charact ', 'littl fire fast easi read kept attent 3/4 book k... even seen nake man revel hard take book serious ', \"n't finish meander stori \", 'love book holden caulfield told point view made ...hospit end book hope feel thing would get better ', \"probabl one depress book 've read ... yet see ra...t said hit home run book long 's 'fiction reader \", \"crazi disgust crazi disturb ca n't even explain ...ca thriller categori 'll happili put vote toward \", 'antihero ye icon teenag rebellion mayb icon futu...ayb good idea shove throat eighth grader probabl ', \"book religi could n't even finish almost alway finish book \", 'couldn\\x92t get book much hype blah realli want like ', ...], y=array([ 1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  ...0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.]), **fit_params={})\n    254         self : Pipeline\n    255             This estimator\n    256         \"\"\"\n    257         Xt, fit_params = self._fit(X, y, **fit_params)\n    258         if self._final_estimator is not None:\n--> 259             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method GaussianNB.fit of GaussianNB(priors=None)>\n        Xt = <298x22 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>\n        y = array([ 1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  ...0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.])\n        fit_params = {}\n    260         return self\n    261 \n    262     def fit_transform(self, X, y=None, **fit_params):\n    263         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py in fit(self=GaussianNB(priors=None), X=<298x22 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>, y=array([ 1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  ...0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.]), sample_weight=None)\n    178         Returns\n    179         -------\n    180         self : object\n    181             Returns self.\n    182         \"\"\"\n--> 183         X, y = check_X_y(X, y)\n        X = <298x22 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>\n        y = array([ 1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  ...0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.])\n    184         return self._partial_fit(X, y, np.unique(y), _refit=True,\n    185                                  sample_weight=sample_weight)\n    186 \n    187     @staticmethod\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py in check_X_y(X=<298x22 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>, y=array([ 1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  ...0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.]), accept_sparse=False, dtype='numeric', order=None, copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, multi_output=False, ensure_min_samples=1, ensure_min_features=1, y_numeric=False, warn_on_dtype=False, estimator=None)\n    537     y_converted : object\n    538         The converted and validated y.\n    539     \"\"\"\n    540     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n    541                     ensure_2d, allow_nd, ensure_min_samples,\n--> 542                     ensure_min_features, warn_on_dtype, estimator)\n        ensure_min_features = 1\n        warn_on_dtype = False\n        estimator = None\n    543     if multi_output:\n    544         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n    545                         dtype=None)\n    546     else:\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py in check_array(array=<298x22 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>, accept_sparse=False, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)\n    395         estimator_name = \"Estimator\"\n    396     context = \" by %s\" % estimator_name if estimator is not None else \"\"\n    397 \n    398     if sp.issparse(array):\n    399         array = _ensure_sparse_format(array, accept_sparse, dtype, copy,\n--> 400                                       force_all_finite)\n        force_all_finite = True\n    401     else:\n    402         array = np.array(array, dtype=dtype, order=order, copy=copy)\n    403 \n    404         if ensure_2d:\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py in _ensure_sparse_format(spmatrix=<298x22 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>, accept_sparse=False, dtype=dtype('float64'), copy=False, force_all_finite=True)\n    239 \n    240     if isinstance(accept_sparse, six.string_types):\n    241         accept_sparse = [accept_sparse]\n    242 \n    243     if accept_sparse is False:\n--> 244         raise TypeError('A sparse matrix was passed, but dense '\n    245                         'data is required. Use X.toarray() to '\n    246                         'convert to a dense numpy array.')\n    247     elif isinstance(accept_sparse, (list, tuple)):\n    248         if len(accept_sparse) == 0:\n\nTypeError: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJoblibTypeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-bd8e5ab9a579>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m                    random_state=42, n_jobs = -1)\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# Fit the random search model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mrandSearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainTxt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrTarg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mbest_random\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandSearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    636\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    637\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 638\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    639\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibTypeError\u001b[0m: JoblibTypeError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x000000E5F37F0C90, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\A...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x000000E5F37F0C90, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\A...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...int(metrics.confusion_matrix(tsTarg, predicted))\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 10, 31, 3, 19, 44, 458506, tzinfo=tzutc()), 'msg_id': '8B1CF3289B42457C8802C240F2E03DCA', 'msg_type': 'execute_request', 'session': '37C2346CBD894BB6AFC06AF5C68B8DE2', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '8B1CF3289B42457C8802C240F2E03DCA', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'37C2346CBD894BB6AFC06AF5C68B8DE2']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...int(metrics.confusion_matrix(tsTarg, predicted))\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 10, 31, 3, 19, 44, 458506, tzinfo=tzutc()), 'msg_id': '8B1CF3289B42457C8802C240F2E03DCA', 'msg_type': 'execute_request', 'session': '37C2346CBD894BB6AFC06AF5C68B8DE2', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '8B1CF3289B42457C8802C240F2E03DCA', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'37C2346CBD894BB6AFC06AF5C68B8DE2'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...int(metrics.confusion_matrix(tsTarg, predicted))\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 10, 31, 3, 19, 44, 458506, tzinfo=tzutc()), 'msg_id': '8B1CF3289B42457C8802C240F2E03DCA', 'msg_type': 'execute_request', 'session': '37C2346CBD894BB6AFC06AF5C68B8DE2', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '8B1CF3289B42457C8802C240F2E03DCA', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...int(metrics.confusion_matrix(tsTarg, predicted))\\n', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...int(metrics.confusion_matrix(tsTarg, predicted))\\n'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...int(metrics.confusion_matrix(tsTarg, predicted))\\n',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...int(metrics.confusion_matrix(tsTarg, predicted))\\n',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...int(metrics.confusion_matrix(tsTarg, predicted))\\n', store_history=True, silent=False, shell_futures=True)\n   2693                 self.displayhook.exec_result = result\n   2694 \n   2695                 # Execute the user code\n   2696                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2697                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2698                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2699                 \n   2700                 self.last_execution_succeeded = not has_raised\n   2701 \n   2702                 # Reset this so later displayed values do not modify the\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>], cell_name='<ipython-input-19-bd8e5ab9a579>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at e5802ca898, execution..._before_exec=None error_in_exec=None result=None>)\n   2797 \n   2798         try:\n   2799             for i, node in enumerate(to_run_exec):\n   2800                 mod = ast.Module([node])\n   2801                 code = compiler(mod, cell_name, \"exec\")\n-> 2802                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x000000E5FF99E810, file \"<ipython-input-19-bd8e5ab9a579>\", line 15>\n        result = <ExecutionResult object at e5802ca898, execution..._before_exec=None error_in_exec=None result=None>\n   2803                     return True\n   2804 \n   2805             for i, node in enumerate(to_run_interactive):\n   2806                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000000E5FF99E810, file \"<ipython-input-19-bd8e5ab9a579>\", line 15>, result=<ExecutionResult object at e5802ca898, execution..._before_exec=None error_in_exec=None result=None>)\n   2857         outflag = True  # happens in more places, so it's easier as default\n   2858         try:\n   2859             try:\n   2860                 self.hooks.pre_run_code_hook()\n   2861                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2862                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x000000E5FF99E810, file \"<ipython-input-19-bd8e5ab9a579>\", line 15>\n        self.user_global_ns = {'BernoulliNB': <class 'sklearn.naive_bayes.BernoulliNB'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'FreqDist': <class 'nltk.probability.FreqDist'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import nltk\\nfrom nltk.corpus import stopwords\\nfr... import BernoulliNB\\n\\n\\nfrom sklearn import metrics', 'def getData():\\n    \\n    data = pd.read_csv(\"Book...s titles \"Unnamed\"\\n    \\n    return data\\n    \\n    ', 'def addPOS(df, ps):\\n    \\n    taggedTxt = []\\n    ...es(taggedTxt, index = df.index)\\n    return column', 'def tag_txt(txt, ps):\\n    #is passed a string of...taggedLst.append(word)\\n    \\n\\n    return taggedLst', 'def getFeatsCART(series):\\n    \\n    valList = []\\n...es(valList)\\n    \\n    return stemTxtCol\\n\\n    \\n    ', '\\nreviews = getData()\\nps = PorterStemmer()', 'reviews.loc[:, \"pos_stem\"] = addPOS(reviews.loc[...processed, tagged words as a new column of the df', 'reviews.loc[:, \"stemTxtCol\"] = getFeatsCART(reviews.loc[:, \\'pos_stem\\'])', 'txtList = [reviews.loc[:, \"stemTxtCol\"].iloc[i] ...rgArr[:piv]\\ntsTarg = targArr[piv:]\\n        \\n\\n    ', 'mnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2..._)\\nprint(randSearch.best_params_)\\nprint()\\nprint()', 'mnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'bnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'import nltk\\nfrom nltk.corpus import stopwords\\nfr...oulliNB, GaussianNB\\n\\n\\nfrom sklearn import metrics', 'def getData():\\n    \\n    data = pd.read_csv(\"Book...s titles \"Unnamed\"\\n    \\n    return data\\n    \\n    ', 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))'], 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'Out': {}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, ...}\n        self.user_ns = {'BernoulliNB': <class 'sklearn.naive_bayes.BernoulliNB'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'FreqDist': <class 'nltk.probability.FreqDist'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import nltk\\nfrom nltk.corpus import stopwords\\nfr... import BernoulliNB\\n\\n\\nfrom sklearn import metrics', 'def getData():\\n    \\n    data = pd.read_csv(\"Book...s titles \"Unnamed\"\\n    \\n    return data\\n    \\n    ', 'def addPOS(df, ps):\\n    \\n    taggedTxt = []\\n    ...es(taggedTxt, index = df.index)\\n    return column', 'def tag_txt(txt, ps):\\n    #is passed a string of...taggedLst.append(word)\\n    \\n\\n    return taggedLst', 'def getFeatsCART(series):\\n    \\n    valList = []\\n...es(valList)\\n    \\n    return stemTxtCol\\n\\n    \\n    ', '\\nreviews = getData()\\nps = PorterStemmer()', 'reviews.loc[:, \"pos_stem\"] = addPOS(reviews.loc[...processed, tagged words as a new column of the df', 'reviews.loc[:, \"stemTxtCol\"] = getFeatsCART(reviews.loc[:, \\'pos_stem\\'])', 'txtList = [reviews.loc[:, \"stemTxtCol\"].iloc[i] ...rgArr[:piv]\\ntsTarg = targArr[piv:]\\n        \\n\\n    ', 'mnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2..._)\\nprint(randSearch.best_params_)\\nprint()\\nprint()', 'mnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'bnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'import nltk\\nfrom nltk.corpus import stopwords\\nfr...oulliNB, GaussianNB\\n\\n\\nfrom sklearn import metrics', 'def getData():\\n    \\n    data = pd.read_csv(\"Book...s titles \"Unnamed\"\\n    \\n    return data\\n    \\n    ', 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))'], 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'Out': {}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, ...}\n   2863             finally:\n   2864                 # Reset our crash handler in place\n   2865                 sys.excepthook = old_excepthook\n   2866         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\Aubrey\\Documents\\BookReviews\\<ipython-input-19-bd8e5ab9a579> in <module>()\n     10 randSearch = RandomizedSearchCV(estimator = gnb_clf, \n     11                    param_distributions = gnbParams,\n     12                    n_iter = 70, cv = 3, verbose=2,\n     13                    random_state=42, n_jobs = -1)\n     14 # Fit the random search model\n---> 15 randSearch.fit(trainTxt, trTarg)\n     16 \n     17 best_random = randSearch.best_estimator_\n     18 # random_accuracy = evaluate(best_random, \n     19 #                            testTxt,\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self=RandomizedSearchCV(cv=3, error_score='raise',\n  ...return_train_score=True, scoring=None, verbose=2), X=['noth read till 60 put sinc kept get wors oh well ', 'read 80 page book bore ', \"strongli dislik book clich fill stori 've encoun... bit silli 's definit least trope fill part book \", \"second chanc read still dnf could n't continu 'm...i 'll stand movi book n't interest well ... page \", 'basic list refer poorli written fantasi nerd stu...s tacki bland like big bang theori probabl enjoy ', \"3.5 star found stori compel time label emot colo...i come term 's nice littl romanc brew stori well \", 'horribl soap opera void anyth alaska plot conclus reveal first chapter ', 'idea mani peopl gave book five star quick read c...like wast time reason finish book book club pick ', \"good surviv stori quit page-grip work boy bengal... ride extrem difficult condit 's worth read book \", 'dnf hate book read school bye ', 'slow bore far ', 'didn\\x92t like kept wait someth happen writer spent...ess want book end doesn\\x92t amazon give money back ', 'chapter 2 done book garbag ', \"n't like fact everyon 's point veiw kinda lost interest like book jump person person \", 'well go break ', 'pc suck jfc absolut sick death pc regim one oppr...h b far better literatur 21st centuri propaganda ', \"tri read finish read ca n't seem finish \", 'novel moment mainli descript alaska time letter ...hin due much predict novel progress banal surfac ', 'difficult book finish well written read first quarter rent movi finish may get book tape well ', 'audio version book dnf concept realli good listen half got bit gruesom shame want find happen ', ...], y=array([ 1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  ...,  0.,  1.,  0.,\n        0.,  0.,  0.,  0.,  0.]), groups=None, **fit_params={})\n    633                                   return_train_score=self.return_train_score,\n    634                                   return_n_test_samples=True,\n    635                                   return_times=True, return_parameters=False,\n    636                                   error_score=self.error_score)\n    637           for parameters, (train, test) in product(candidate_params,\n--> 638                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=3, random_state=None, shuffle=False)>\n        X = ['noth read till 60 put sinc kept get wors oh well ', 'read 80 page book bore ', \"strongli dislik book clich fill stori 've encoun... bit silli 's definit least trope fill part book \", \"second chanc read still dnf could n't continu 'm...i 'll stand movi book n't interest well ... page \", 'basic list refer poorli written fantasi nerd stu...s tacki bland like big bang theori probabl enjoy ', \"3.5 star found stori compel time label emot colo...i come term 's nice littl romanc brew stori well \", 'horribl soap opera void anyth alaska plot conclus reveal first chapter ', 'idea mani peopl gave book five star quick read c...like wast time reason finish book book club pick ', \"good surviv stori quit page-grip work boy bengal... ride extrem difficult condit 's worth read book \", 'dnf hate book read school bye ', 'slow bore far ', 'didn\\x92t like kept wait someth happen writer spent...ess want book end doesn\\x92t amazon give money back ', 'chapter 2 done book garbag ', \"n't like fact everyon 's point veiw kinda lost interest like book jump person person \", 'well go break ', 'pc suck jfc absolut sick death pc regim one oppr...h b far better literatur 21st centuri propaganda ', \"tri read finish read ca n't seem finish \", 'novel moment mainli descript alaska time letter ...hin due much predict novel progress banal surfac ', 'difficult book finish well written read first quarter rent movi finish may get book tape well ', 'audio version book dnf concept realli good listen half got bit gruesom shame want find happen ', ...]\n        y = array([ 1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  ...,  0.,  1.,  0.,\n        0.,  0.,  0.,  0.,  0.])\n        groups = None\n    639 \n    640         # if one choose to see train score, \"out\" will contain train score info\n    641         if self.return_train_score:\n    642             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nTypeError                                          Tue Oct 30 22:19:45 2018\nPID: 5928                Python 3.6.2: C:\\Users\\Aubrey\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('vect', Count...se_idf=True)), ('clf', GaussianNB(priors=None))]), ['noth read till 60 put sinc kept get wors oh well ', 'read 80 page book bore ', \"strongli dislik book clich fill stori 've encoun... bit silli 's definit least trope fill part book \", \"second chanc read still dnf could n't continu 'm...i 'll stand movi book n't interest well ... page \", 'basic list refer poorli written fantasi nerd stu...s tacki bland like big bang theori probabl enjoy ', \"3.5 star found stori compel time label emot colo...i come term 's nice littl romanc brew stori well \", 'horribl soap opera void anyth alaska plot conclus reveal first chapter ', 'idea mani peopl gave book five star quick read c...like wast time reason finish book book club pick ', \"good surviv stori quit page-grip work boy bengal... ride extrem difficult condit 's worth read book \", 'dnf hate book read school bye ', 'slow bore far ', 'didn\\x92t like kept wait someth happen writer spent...ess want book end doesn\\x92t amazon give money back ', 'chapter 2 done book garbag ', \"n't like fact everyon 's point veiw kinda lost interest like book jump person person \", 'well go break ', 'pc suck jfc absolut sick death pc regim one oppr...h b far better literatur 21st centuri propaganda ', \"tri read finish read ca n't seem finish \", 'novel moment mainli descript alaska time letter ...hin due much predict novel progress banal surfac ', 'difficult book finish well written read first quarter rent movi finish may get book tape well ', 'audio version book dnf concept realli good listen half got bit gruesom shame want find happen ', ...], array([ 1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  ...,  0.,  1.,  0.,\n        0.,  0.,  0.,  0.,  0.]), {'score': <function _passthrough_scorer>}, array([146, 148, 149, 150, 153, 154, 155, 156, 1...37, 438, 439, 440, 441, 442, 443, 444, 445, 446]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 141, 142,\n       143, 144, 145, 147, 151, 152]), 2, {'tfidf__use_idf': True, 'vect__max_features': 22, 'vect__ngram_range': (1, 3)}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('vect', Count...se_idf=True)), ('clf', GaussianNB(priors=None))]), ['noth read till 60 put sinc kept get wors oh well ', 'read 80 page book bore ', \"strongli dislik book clich fill stori 've encoun... bit silli 's definit least trope fill part book \", \"second chanc read still dnf could n't continu 'm...i 'll stand movi book n't interest well ... page \", 'basic list refer poorli written fantasi nerd stu...s tacki bland like big bang theori probabl enjoy ', \"3.5 star found stori compel time label emot colo...i come term 's nice littl romanc brew stori well \", 'horribl soap opera void anyth alaska plot conclus reveal first chapter ', 'idea mani peopl gave book five star quick read c...like wast time reason finish book book club pick ', \"good surviv stori quit page-grip work boy bengal... ride extrem difficult condit 's worth read book \", 'dnf hate book read school bye ', 'slow bore far ', 'didn\\x92t like kept wait someth happen writer spent...ess want book end doesn\\x92t amazon give money back ', 'chapter 2 done book garbag ', \"n't like fact everyon 's point veiw kinda lost interest like book jump person person \", 'well go break ', 'pc suck jfc absolut sick death pc regim one oppr...h b far better literatur 21st centuri propaganda ', \"tri read finish read ca n't seem finish \", 'novel moment mainli descript alaska time letter ...hin due much predict novel progress banal surfac ', 'difficult book finish well written read first quarter rent movi finish may get book tape well ', 'audio version book dnf concept realli good listen half got bit gruesom shame want find happen ', ...], array([ 1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  ...,  0.,  1.,  0.,\n        0.,  0.,  0.,  0.,  0.]), {'score': <function _passthrough_scorer>}, array([146, 148, 149, 150, 153, 154, 155, 156, 1...37, 438, 439, 440, 441, 442, 443, 444, 445, 446]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 141, 142,\n       143, 144, 145, 147, 151, 152]), 2, {'tfidf__use_idf': True, 'vect__max_features': 22, 'vect__ngram_range': (1, 3)})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('vect', Count...se_idf=True)), ('clf', GaussianNB(priors=None))]), X=['noth read till 60 put sinc kept get wors oh well ', 'read 80 page book bore ', \"strongli dislik book clich fill stori 've encoun... bit silli 's definit least trope fill part book \", \"second chanc read still dnf could n't continu 'm...i 'll stand movi book n't interest well ... page \", 'basic list refer poorli written fantasi nerd stu...s tacki bland like big bang theori probabl enjoy ', \"3.5 star found stori compel time label emot colo...i come term 's nice littl romanc brew stori well \", 'horribl soap opera void anyth alaska plot conclus reveal first chapter ', 'idea mani peopl gave book five star quick read c...like wast time reason finish book book club pick ', \"good surviv stori quit page-grip work boy bengal... ride extrem difficult condit 's worth read book \", 'dnf hate book read school bye ', 'slow bore far ', 'didn\\x92t like kept wait someth happen writer spent...ess want book end doesn\\x92t amazon give money back ', 'chapter 2 done book garbag ', \"n't like fact everyon 's point veiw kinda lost interest like book jump person person \", 'well go break ', 'pc suck jfc absolut sick death pc regim one oppr...h b far better literatur 21st centuri propaganda ', \"tri read finish read ca n't seem finish \", 'novel moment mainli descript alaska time letter ...hin due much predict novel progress banal surfac ', 'difficult book finish well written read first quarter rent movi finish may get book tape well ', 'audio version book dnf concept realli good listen half got bit gruesom shame want find happen ', ...], y=array([ 1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  ...,  0.,  1.,  0.,\n        0.,  0.,  0.,  0.,  0.]), scorer={'score': <function _passthrough_scorer>}, train=array([146, 148, 149, 150, 153, 154, 155, 156, 1...37, 438, 439, 440, 441, 442, 443, 444, 445, 446]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 141, 142,\n       143, 144, 145, 147, 151, 152]), verbose=2, parameters={'tfidf__use_idf': True, 'vect__max_features': 22, 'vect__ngram_range': (1, 3)}, fit_params={}, return_train_score=True, return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    432 \n    433     try:\n    434         if y_train is None:\n    435             estimator.fit(X_train, **fit_params)\n    436         else:\n--> 437             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...e_idf=True)), ('clf', GaussianNB(priors=None))])>\n        X_train = [\"mini review dnf x2 book circul gr sinc end 2017....at\\x92 overal realli didn\\x92t like book n't recommend \", \"could n't finish \", \"melodramat improb n't finish \", \"could n't get past page 64. flat bore n't like write style \", \"wow..al say brilliant ca n't wait next one may n...seri know find gem read book one sit forgo sleep \", 'finish book put read coupl chapter thought mayb ...ory- none well develop overal found stori bizarr ', 'excel book great studi frailti strength human be...el reader least case would highli recommend book ', \"talent writer hollywood love 3 star sound like p...i would case like would n't left gum-sho partner \", \"n't throw mani book away ... .but one went trash ... depress gave ... 's read \", 'ugh ... ..could finish ', \"50 novel main charact explain minutia random 80 trivia ridicul sad finish 20 book could n't go \", 'love celest ng\\x92 first book everyth never told lo...pt appear end unbeliev izzi one teen age charact ', 'littl fire fast easi read kept attent 3/4 book k... even seen nake man revel hard take book serious ', \"n't finish meander stori \", 'love book holden caulfield told point view made ...hospit end book hope feel thing would get better ', \"probabl one depress book 've read ... yet see ra...t said hit home run book long 's 'fiction reader \", \"crazi disgust crazi disturb ca n't even explain ...ca thriller categori 'll happili put vote toward \", 'antihero ye icon teenag rebellion mayb icon futu...ayb good idea shove throat eighth grader probabl ', \"book religi could n't even finish almost alway finish book \", 'couldn\\x92t get book much hype blah realli want like ', ...]\n        y_train = array([ 1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  ...0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.])\n        fit_params = {}\n    438 \n    439     except Exception as e:\n    440         # Note fit time as time until error\n    441         fit_time = time.time() - start_time\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('vect', Count...se_idf=True)), ('clf', GaussianNB(priors=None))]), X=[\"mini review dnf x2 book circul gr sinc end 2017....at\\x92 overal realli didn\\x92t like book n't recommend \", \"could n't finish \", \"melodramat improb n't finish \", \"could n't get past page 64. flat bore n't like write style \", \"wow..al say brilliant ca n't wait next one may n...seri know find gem read book one sit forgo sleep \", 'finish book put read coupl chapter thought mayb ...ory- none well develop overal found stori bizarr ', 'excel book great studi frailti strength human be...el reader least case would highli recommend book ', \"talent writer hollywood love 3 star sound like p...i would case like would n't left gum-sho partner \", \"n't throw mani book away ... .but one went trash ... depress gave ... 's read \", 'ugh ... ..could finish ', \"50 novel main charact explain minutia random 80 trivia ridicul sad finish 20 book could n't go \", 'love celest ng\\x92 first book everyth never told lo...pt appear end unbeliev izzi one teen age charact ', 'littl fire fast easi read kept attent 3/4 book k... even seen nake man revel hard take book serious ', \"n't finish meander stori \", 'love book holden caulfield told point view made ...hospit end book hope feel thing would get better ', \"probabl one depress book 've read ... yet see ra...t said hit home run book long 's 'fiction reader \", \"crazi disgust crazi disturb ca n't even explain ...ca thriller categori 'll happili put vote toward \", 'antihero ye icon teenag rebellion mayb icon futu...ayb good idea shove throat eighth grader probabl ', \"book religi could n't even finish almost alway finish book \", 'couldn\\x92t get book much hype blah realli want like ', ...], y=array([ 1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  ...0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.]), **fit_params={})\n    254         self : Pipeline\n    255             This estimator\n    256         \"\"\"\n    257         Xt, fit_params = self._fit(X, y, **fit_params)\n    258         if self._final_estimator is not None:\n--> 259             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method GaussianNB.fit of GaussianNB(priors=None)>\n        Xt = <298x22 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>\n        y = array([ 1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  ...0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.])\n        fit_params = {}\n    260         return self\n    261 \n    262     def fit_transform(self, X, y=None, **fit_params):\n    263         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py in fit(self=GaussianNB(priors=None), X=<298x22 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>, y=array([ 1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  ...0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.]), sample_weight=None)\n    178         Returns\n    179         -------\n    180         self : object\n    181             Returns self.\n    182         \"\"\"\n--> 183         X, y = check_X_y(X, y)\n        X = <298x22 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>\n        y = array([ 1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  ...0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.])\n    184         return self._partial_fit(X, y, np.unique(y), _refit=True,\n    185                                  sample_weight=sample_weight)\n    186 \n    187     @staticmethod\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py in check_X_y(X=<298x22 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>, y=array([ 1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  ...0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.]), accept_sparse=False, dtype='numeric', order=None, copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, multi_output=False, ensure_min_samples=1, ensure_min_features=1, y_numeric=False, warn_on_dtype=False, estimator=None)\n    537     y_converted : object\n    538         The converted and validated y.\n    539     \"\"\"\n    540     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n    541                     ensure_2d, allow_nd, ensure_min_samples,\n--> 542                     ensure_min_features, warn_on_dtype, estimator)\n        ensure_min_features = 1\n        warn_on_dtype = False\n        estimator = None\n    543     if multi_output:\n    544         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n    545                         dtype=None)\n    546     else:\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py in check_array(array=<298x22 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>, accept_sparse=False, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)\n    395         estimator_name = \"Estimator\"\n    396     context = \" by %s\" % estimator_name if estimator is not None else \"\"\n    397 \n    398     if sp.issparse(array):\n    399         array = _ensure_sparse_format(array, accept_sparse, dtype, copy,\n--> 400                                       force_all_finite)\n        force_all_finite = True\n    401     else:\n    402         array = np.array(array, dtype=dtype, order=order, copy=copy)\n    403 \n    404         if ensure_2d:\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py in _ensure_sparse_format(spmatrix=<298x22 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>, accept_sparse=False, dtype=dtype('float64'), copy=False, force_all_finite=True)\n    239 \n    240     if isinstance(accept_sparse, six.string_types):\n    241         accept_sparse = [accept_sparse]\n    242 \n    243     if accept_sparse is False:\n--> 244         raise TypeError('A sparse matrix was passed, but dense '\n    245                         'data is required. Use X.toarray() to '\n    246                         'convert to a dense numpy array.')\n    247     elif isinstance(accept_sparse, (list, tuple)):\n    248         if len(accept_sparse) == 0:\n\nTypeError: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2), (1,3), (1,4)],\n",
    "            'vect__max_features': [i+15 for i in range(10)],\n",
    "            \"tfidf__use_idf\": (True, False)}\n",
    "#\"clf__alpha\": np.arange(10^-10, 10^-8, (10^-8 - 10^-10)/10)}\n",
    "\n",
    "gnb_clf = Pipeline([('vect', CountVectorizer()), \n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', GaussianNB())])\n",
    "\n",
    "randSearch = RandomizedSearchCV(estimator = gnb_clf, \n",
    "                   param_distributions = gnbParams,\n",
    "                   n_iter = 70, cv = 3, verbose=2,\n",
    "                   random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "randSearch.fit(trainTxt, trTarg)\n",
    "\n",
    "best_random = randSearch.best_estimator_\n",
    "# random_accuracy = evaluate(best_random, \n",
    "#                            testTxt,\n",
    "#                            tsTarg)\n",
    "\n",
    "_ = best_random.fit(trainTxt, trTarg)\n",
    "\n",
    "predicted = best_random.predict(testTxt)\n",
    "\n",
    "\n",
    "print(randSearch.best_score_)\n",
    "print(randSearch.best_params_)\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print(np.mean(predicted == tsTarg))\n",
    "print()\n",
    "print(\"classification report\")\n",
    "print(metrics.classification_report(tsTarg, predicted))\n",
    "print()\n",
    "print(\"confusion mtx\")\n",
    "print(metrics.confusion_matrix(tsTarg, predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.686750085121\n",
      "{'tfidf__use_idf': True, 'vect__max_features': 18, 'vect__ngram_range': (1, 1)}\n",
      "\n",
      "\n",
      "0.733333333333\n",
      "\n",
      "classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.71      1.00      0.83        99\n",
      "        1.0       1.00      0.22      0.35        51\n",
      "\n",
      "avg / total       0.81      0.73      0.67       150\n",
      "\n",
      "\n",
      "confusion mtx\n",
      "[[99  0]\n",
      " [40 11]]\n"
     ]
    }
   ],
   "source": [
    "svcParams = {\"vect__ngram_range\": [(1, 1), (1, 2), (1,3), (1,4)],\n",
    "            'vect__max_features': [i+15 for i in range(10)],\n",
    "            \"tfidf__use_idf\": (True, False)}\n",
    "\n",
    "svc_clf = Pipeline([('vect', CountVectorizer()), \n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SVC())])\n",
    "\n",
    "\n",
    "svc_clf = GridSearchCV(svc_clf, svcParams,\n",
    "                      cv=5, iid=False, n_jobs=-1)\n",
    "svc_clf = svc_clf.fit(trainTxt, trTarg)\n",
    "print(svc_clf.best_score_)\n",
    "print(svc_clf.best_params_) \n",
    "\n",
    "best = svc_clf.best_estimator_\n",
    "_ = best.fit(trainTxt, trTarg)\n",
    "\n",
    "predicted = best.predict(testTxt)\n",
    "\n",
    "\n",
    " \n",
    "# randSearch = RandomizedSearchCV(estimator = svc_clf, \n",
    "#                    param_distributions = svcParams,\n",
    "#                    n_iter = 100, cv = 3, verbose=2,\n",
    "#                    random_state=42, n_jobs = -1)\n",
    "# # Fit the random search model\n",
    "# randSearch.fit(trainTxt, trTarg)\n",
    "\n",
    "# best_random = randSearch.best_estimator_\n",
    "# # random_accuracy = evaluate(best_random, \n",
    "# #                            testTxt,\n",
    "# #                            tsTarg)\n",
    "\n",
    "# _ = best_random.fit(trainTxt, trTarg)\n",
    "\n",
    "# predicted = best_random.predict(testTxt)\n",
    "\n",
    "\n",
    "# print(randSearch.best_score_)\n",
    "# print(randSearch.best_params_)\n",
    "# print()\n",
    "# print()\n",
    "print()\n",
    "print()\n",
    "print(np.mean(predicted == tsTarg))\n",
    "print()\n",
    "print(\"classification report\")\n",
    "print(metrics.classification_report(tsTarg, predicted))\n",
    "print()\n",
    "print(\"confusion mtx\")\n",
    "print(metrics.confusion_matrix(tsTarg, predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.686750085121\n",
      "{'clf__degree': 1, 'tfidf__use_idf': True, 'vect__max_features': 18, 'vect__ngram_range': (1, 1)}\n",
      "\n",
      "\n",
      "0.733333333333\n",
      "\n",
      "classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.71      1.00      0.83        99\n",
      "        1.0       1.00      0.22      0.35        51\n",
      "\n",
      "avg / total       0.81      0.73      0.67       150\n",
      "\n",
      "\n",
      "confusion mtx\n",
      "[[99  0]\n",
      " [40 11]]\n"
     ]
    }
   ],
   "source": [
    "svcParams = {\"vect__ngram_range\": [(1, 1), (1, 2), (1,3), (1,4)],\n",
    "            'vect__max_features': [i+15 for i in range(10)],\n",
    "            \"tfidf__use_idf\": (True, False), \n",
    "            \"clf__degree\": [i+1 for i in range(4)]}\n",
    "\n",
    "svc_clf = Pipeline([('vect', CountVectorizer()), \n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SVC())])\n",
    "\n",
    "\n",
    "svc_clf = GridSearchCV(svc_clf, svcParams,\n",
    "                      cv=5, iid=False, n_jobs=-1)\n",
    "svc_clf = svc_clf.fit(trainTxt, trTarg)\n",
    "print(svc_clf.best_score_)\n",
    "print(svc_clf.best_params_) \n",
    "\n",
    "best = svc_clf.best_estimator_\n",
    "_ = best.fit(trainTxt, trTarg)\n",
    "\n",
    "predicted = best.predict(testTxt)\n",
    "\n",
    "\n",
    " \n",
    "# randSearch = RandomizedSearchCV(estimator = svc_clf, \n",
    "#                    param_distributions = svcParams,\n",
    "#                    n_iter = 100, cv = 3, verbose=2,\n",
    "#                    random_state=42, n_jobs = -1)\n",
    "# # Fit the random search model\n",
    "# randSearch.fit(trainTxt, trTarg)\n",
    "\n",
    "# best_random = randSearch.best_estimator_\n",
    "# # random_accuracy = evaluate(best_random, \n",
    "# #                            testTxt,\n",
    "# #                            tsTarg)\n",
    "\n",
    "# _ = best_random.fit(trainTxt, trTarg)\n",
    "\n",
    "# predicted = best_random.predict(testTxt)\n",
    "\n",
    "\n",
    "# print(randSearch.best_score_)\n",
    "# print(randSearch.best_params_)\n",
    "# print()\n",
    "# print()\n",
    "print()\n",
    "print()\n",
    "print(np.mean(predicted == tsTarg))\n",
    "print()\n",
    "print(\"classification report\")\n",
    "print(metrics.classification_report(tsTarg, predicted))\n",
    "print()\n",
    "print(\"confusion mtx\")\n",
    "print(metrics.confusion_matrix(tsTarg, predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x000000E5F37F0C90, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\A...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x000000E5F37F0C90, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\A...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'nsvcParams = {\"vect__ngram_range\": [(1, 1), (1, ...int(metrics.confusion_matrix(tsTarg, predicted))\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 10, 31, 3, 51, 45, 706495, tzinfo=tzutc()), 'msg_id': '5374905733F643A98B27158BFB560F81', 'msg_type': 'execute_request', 'session': '37C2346CBD894BB6AFC06AF5C68B8DE2', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '5374905733F643A98B27158BFB560F81', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'37C2346CBD894BB6AFC06AF5C68B8DE2']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'nsvcParams = {\"vect__ngram_range\": [(1, 1), (1, ...int(metrics.confusion_matrix(tsTarg, predicted))\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 10, 31, 3, 51, 45, 706495, tzinfo=tzutc()), 'msg_id': '5374905733F643A98B27158BFB560F81', 'msg_type': 'execute_request', 'session': '37C2346CBD894BB6AFC06AF5C68B8DE2', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '5374905733F643A98B27158BFB560F81', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'37C2346CBD894BB6AFC06AF5C68B8DE2'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'nsvcParams = {\"vect__ngram_range\": [(1, 1), (1, ...int(metrics.confusion_matrix(tsTarg, predicted))\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 10, 31, 3, 51, 45, 706495, tzinfo=tzutc()), 'msg_id': '5374905733F643A98B27158BFB560F81', 'msg_type': 'execute_request', 'session': '37C2346CBD894BB6AFC06AF5C68B8DE2', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '5374905733F643A98B27158BFB560F81', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='nsvcParams = {\"vect__ngram_range\": [(1, 1), (1, ...int(metrics.confusion_matrix(tsTarg, predicted))\\n', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'nsvcParams = {\"vect__ngram_range\": [(1, 1), (1, ...int(metrics.confusion_matrix(tsTarg, predicted))\\n'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('nsvcParams = {\"vect__ngram_range\": [(1, 1), (1, ...int(metrics.confusion_matrix(tsTarg, predicted))\\n',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('nsvcParams = {\"vect__ngram_range\": [(1, 1), (1, ...int(metrics.confusion_matrix(tsTarg, predicted))\\n',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='nsvcParams = {\"vect__ngram_range\": [(1, 1), (1, ...int(metrics.confusion_matrix(tsTarg, predicted))\\n', store_history=True, silent=False, shell_futures=True)\n   2693                 self.displayhook.exec_result = result\n   2694 \n   2695                 # Execute the user code\n   2696                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2697                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2698                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2699                 \n   2700                 self.last_execution_succeeded = not has_raised\n   2701 \n   2702                 # Reset this so later displayed values do not modify the\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>], cell_name='<ipython-input-33-669f61581e5d>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at e58032b0f0, execution..._before_exec=None error_in_exec=None result=None>)\n   2797 \n   2798         try:\n   2799             for i, node in enumerate(to_run_exec):\n   2800                 mod = ast.Module([node])\n   2801                 code = compiler(mod, cell_name, \"exec\")\n-> 2802                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x000000E5FFB47F60, file \"<ipython-input-33-669f61581e5d>\", line 14>\n        result = <ExecutionResult object at e58032b0f0, execution..._before_exec=None error_in_exec=None result=None>\n   2803                     return True\n   2804 \n   2805             for i, node in enumerate(to_run_interactive):\n   2806                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000000E5FFB47F60, file \"<ipython-input-33-669f61581e5d>\", line 14>, result=<ExecutionResult object at e58032b0f0, execution..._before_exec=None error_in_exec=None result=None>)\n   2857         outflag = True  # happens in more places, so it's easier as default\n   2858         try:\n   2859             try:\n   2860                 self.hooks.pre_run_code_hook()\n   2861                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2862                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x000000E5FFB47F60, file \"<ipython-input-33-669f61581e5d>\", line 14>\n        self.user_global_ns = {'BernoulliNB': <class 'sklearn.naive_bayes.BernoulliNB'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'FreqDist': <class 'nltk.probability.FreqDist'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import nltk\\nfrom nltk.corpus import stopwords\\nfr... import BernoulliNB\\n\\n\\nfrom sklearn import metrics', 'def getData():\\n    \\n    data = pd.read_csv(\"Book...s titles \"Unnamed\"\\n    \\n    return data\\n    \\n    ', 'def addPOS(df, ps):\\n    \\n    taggedTxt = []\\n    ...es(taggedTxt, index = df.index)\\n    return column', 'def tag_txt(txt, ps):\\n    #is passed a string of...taggedLst.append(word)\\n    \\n\\n    return taggedLst', 'def getFeatsCART(series):\\n    \\n    valList = []\\n...es(valList)\\n    \\n    return stemTxtCol\\n\\n    \\n    ', '\\nreviews = getData()\\nps = PorterStemmer()', 'reviews.loc[:, \"pos_stem\"] = addPOS(reviews.loc[...processed, tagged words as a new column of the df', 'reviews.loc[:, \"stemTxtCol\"] = getFeatsCART(reviews.loc[:, \\'pos_stem\\'])', 'txtList = [reviews.loc[:, \"stemTxtCol\"].iloc[i] ...rgArr[:piv]\\ntsTarg = targArr[piv:]\\n        \\n\\n    ', 'mnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2..._)\\nprint(randSearch.best_params_)\\nprint()\\nprint()', 'mnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'bnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'import nltk\\nfrom nltk.corpus import stopwords\\nfr...oulliNB, GaussianNB\\n\\n\\nfrom sklearn import metrics', 'def getData():\\n    \\n    data = pd.read_csv(\"Book...s titles \"Unnamed\"\\n    \\n    return data\\n    \\n    ', 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', ...], 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'NuSVC': <class 'sklearn.svm.classes.NuSVC'>, ...}\n        self.user_ns = {'BernoulliNB': <class 'sklearn.naive_bayes.BernoulliNB'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'FreqDist': <class 'nltk.probability.FreqDist'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import nltk\\nfrom nltk.corpus import stopwords\\nfr... import BernoulliNB\\n\\n\\nfrom sklearn import metrics', 'def getData():\\n    \\n    data = pd.read_csv(\"Book...s titles \"Unnamed\"\\n    \\n    return data\\n    \\n    ', 'def addPOS(df, ps):\\n    \\n    taggedTxt = []\\n    ...es(taggedTxt, index = df.index)\\n    return column', 'def tag_txt(txt, ps):\\n    #is passed a string of...taggedLst.append(word)\\n    \\n\\n    return taggedLst', 'def getFeatsCART(series):\\n    \\n    valList = []\\n...es(valList)\\n    \\n    return stemTxtCol\\n\\n    \\n    ', '\\nreviews = getData()\\nps = PorterStemmer()', 'reviews.loc[:, \"pos_stem\"] = addPOS(reviews.loc[...processed, tagged words as a new column of the df', 'reviews.loc[:, \"stemTxtCol\"] = getFeatsCART(reviews.loc[:, \\'pos_stem\\'])', 'txtList = [reviews.loc[:, \"stemTxtCol\"].iloc[i] ...rgArr[:piv]\\ntsTarg = targArr[piv:]\\n        \\n\\n    ', 'mnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2..._)\\nprint(randSearch.best_params_)\\nprint()\\nprint()', 'mnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'bnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'import nltk\\nfrom nltk.corpus import stopwords\\nfr...oulliNB, GaussianNB\\n\\n\\nfrom sklearn import metrics', 'def getData():\\n    \\n    data = pd.read_csv(\"Book...s titles \"Unnamed\"\\n    \\n    return data\\n    \\n    ', 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', ...], 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'NuSVC': <class 'sklearn.svm.classes.NuSVC'>, ...}\n   2863             finally:\n   2864                 # Reset our crash handler in place\n   2865                 sys.excepthook = old_excepthook\n   2866         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\Aubrey\\Documents\\BookReviews\\<ipython-input-33-669f61581e5d> in <module>()\n      9                      ('clf', SVC())])\n     10 \n     11 \n     12 nsvc_clf = GridSearchCV(nsvc_clf, nsvcParams,\n     13                       cv=5, iid=False, n_jobs=-1)\n---> 14 nsvc_clf = nsvc_clf.fit(trainTxt, trTarg)\n     15 print(nsvc_clf.best_score_)\n     16 print(nsvc_clf.best_params_) \n     17 \n     18 best = nsvc_clf.best_estimator_\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=0), X=['noth read till 60 put sinc kept get wors oh well ', 'read 80 page book bore ', \"strongli dislik book clich fill stori 've encoun... bit silli 's definit least trope fill part book \", \"second chanc read still dnf could n't continu 'm...i 'll stand movi book n't interest well ... page \", 'basic list refer poorli written fantasi nerd stu...s tacki bland like big bang theori probabl enjoy ', \"3.5 star found stori compel time label emot colo...i come term 's nice littl romanc brew stori well \", 'horribl soap opera void anyth alaska plot conclus reveal first chapter ', 'idea mani peopl gave book five star quick read c...like wast time reason finish book book club pick ', \"good surviv stori quit page-grip work boy bengal... ride extrem difficult condit 's worth read book \", 'dnf hate book read school bye ', 'slow bore far ', 'didn\\x92t like kept wait someth happen writer spent...ess want book end doesn\\x92t amazon give money back ', 'chapter 2 done book garbag ', \"n't like fact everyon 's point veiw kinda lost interest like book jump person person \", 'well go break ', 'pc suck jfc absolut sick death pc regim one oppr...h b far better literatur 21st centuri propaganda ', \"tri read finish read ca n't seem finish \", 'novel moment mainli descript alaska time letter ...hin due much predict novel progress banal surfac ', 'difficult book finish well written read first quarter rent movi finish may get book tape well ', 'audio version book dnf concept realli good listen half got bit gruesom shame want find happen ', ...], y=array([ 1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  ...,  0.,  1.,  0.,\n        0.,  0.,  0.,  0.,  0.]), groups=None, **fit_params={})\n    633                                   return_train_score=self.return_train_score,\n    634                                   return_n_test_samples=True,\n    635                                   return_times=True, return_parameters=False,\n    636                                   error_score=self.error_score)\n    637           for parameters, (train, test) in product(candidate_params,\n--> 638                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=5, random_state=None, shuffle=False)>\n        X = ['noth read till 60 put sinc kept get wors oh well ', 'read 80 page book bore ', \"strongli dislik book clich fill stori 've encoun... bit silli 's definit least trope fill part book \", \"second chanc read still dnf could n't continu 'm...i 'll stand movi book n't interest well ... page \", 'basic list refer poorli written fantasi nerd stu...s tacki bland like big bang theori probabl enjoy ', \"3.5 star found stori compel time label emot colo...i come term 's nice littl romanc brew stori well \", 'horribl soap opera void anyth alaska plot conclus reveal first chapter ', 'idea mani peopl gave book five star quick read c...like wast time reason finish book book club pick ', \"good surviv stori quit page-grip work boy bengal... ride extrem difficult condit 's worth read book \", 'dnf hate book read school bye ', 'slow bore far ', 'didn\\x92t like kept wait someth happen writer spent...ess want book end doesn\\x92t amazon give money back ', 'chapter 2 done book garbag ', \"n't like fact everyon 's point veiw kinda lost interest like book jump person person \", 'well go break ', 'pc suck jfc absolut sick death pc regim one oppr...h b far better literatur 21st centuri propaganda ', \"tri read finish read ca n't seem finish \", 'novel moment mainli descript alaska time letter ...hin due much predict novel progress banal surfac ', 'difficult book finish well written read first quarter rent movi finish may get book tape well ', 'audio version book dnf concept realli good listen half got bit gruesom shame want find happen ', ...]\n        y = array([ 1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  ...,  0.,  1.,  0.,\n        0.,  0.,  0.,  0.,  0.])\n        groups = None\n    639 \n    640         # if one choose to see train score, \"out\" will contain train score info\n    641         if self.return_train_score:\n    642             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Tue Oct 30 22:51:46 2018\nPID: 7424                Python 3.6.2: C:\\Users\\Aubrey\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('vect', Count...e, shrinking=True,\n  tol=0.001, verbose=False))]), ['noth read till 60 put sinc kept get wors oh well ', 'read 80 page book bore ', \"strongli dislik book clich fill stori 've encoun... bit silli 's definit least trope fill part book \", \"second chanc read still dnf could n't continu 'm...i 'll stand movi book n't interest well ... page \", 'basic list refer poorli written fantasi nerd stu...s tacki bland like big bang theori probabl enjoy ', \"3.5 star found stori compel time label emot colo...i come term 's nice littl romanc brew stori well \", 'horribl soap opera void anyth alaska plot conclus reveal first chapter ', 'idea mani peopl gave book five star quick read c...like wast time reason finish book book club pick ', \"good surviv stori quit page-grip work boy bengal... ride extrem difficult condit 's worth read book \", 'dnf hate book read school bye ', 'slow bore far ', 'didn\\x92t like kept wait someth happen writer spent...ess want book end doesn\\x92t amazon give money back ', 'chapter 2 done book garbag ', \"n't like fact everyon 's point veiw kinda lost interest like book jump person person \", 'well go break ', 'pc suck jfc absolut sick death pc regim one oppr...h b far better literatur 21st centuri propaganda ', \"tri read finish read ca n't seem finish \", 'novel moment mainli descript alaska time letter ...hin due much predict novel progress banal surfac ', 'difficult book finish well written read first quarter rent movi finish may get book tape well ', 'audio version book dnf concept realli good listen half got bit gruesom shame want find happen ', ...], array([ 1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  ...,  0.,  1.,  0.,\n        0.,  0.,  0.,  0.,  0.]), {'score': <function _passthrough_scorer>}, array([ 88,  90,  91,  92,  94,  95,  96,  97,  ..., 439, 440,\n       441, 442, 443, 444, 445, 446]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1..., 80, 81, 82, 83, 84,\n       85, 86, 87, 89, 93]), 0, {'clf__degree': 1, 'clf_nu__': 0.20000000000000001, 'tfidf__use_idf': True, 'vect__max_features': 15, 'vect__ngram_range': (1, 1)}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('vect', Count...e, shrinking=True,\n  tol=0.001, verbose=False))]), ['noth read till 60 put sinc kept get wors oh well ', 'read 80 page book bore ', \"strongli dislik book clich fill stori 've encoun... bit silli 's definit least trope fill part book \", \"second chanc read still dnf could n't continu 'm...i 'll stand movi book n't interest well ... page \", 'basic list refer poorli written fantasi nerd stu...s tacki bland like big bang theori probabl enjoy ', \"3.5 star found stori compel time label emot colo...i come term 's nice littl romanc brew stori well \", 'horribl soap opera void anyth alaska plot conclus reveal first chapter ', 'idea mani peopl gave book five star quick read c...like wast time reason finish book book club pick ', \"good surviv stori quit page-grip work boy bengal... ride extrem difficult condit 's worth read book \", 'dnf hate book read school bye ', 'slow bore far ', 'didn\\x92t like kept wait someth happen writer spent...ess want book end doesn\\x92t amazon give money back ', 'chapter 2 done book garbag ', \"n't like fact everyon 's point veiw kinda lost interest like book jump person person \", 'well go break ', 'pc suck jfc absolut sick death pc regim one oppr...h b far better literatur 21st centuri propaganda ', \"tri read finish read ca n't seem finish \", 'novel moment mainli descript alaska time letter ...hin due much predict novel progress banal surfac ', 'difficult book finish well written read first quarter rent movi finish may get book tape well ', 'audio version book dnf concept realli good listen half got bit gruesom shame want find happen ', ...], array([ 1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  ...,  0.,  1.,  0.,\n        0.,  0.,  0.,  0.,  0.]), {'score': <function _passthrough_scorer>}, array([ 88,  90,  91,  92,  94,  95,  96,  97,  ..., 439, 440,\n       441, 442, 443, 444, 445, 446]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1..., 80, 81, 82, 83, 84,\n       85, 86, 87, 89, 93]), 0, {'clf__degree': 1, 'clf_nu__': 0.20000000000000001, 'tfidf__use_idf': True, 'vect__max_features': 15, 'vect__ngram_range': (1, 1)})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('vect', Count...e, shrinking=True,\n  tol=0.001, verbose=False))]), X=['noth read till 60 put sinc kept get wors oh well ', 'read 80 page book bore ', \"strongli dislik book clich fill stori 've encoun... bit silli 's definit least trope fill part book \", \"second chanc read still dnf could n't continu 'm...i 'll stand movi book n't interest well ... page \", 'basic list refer poorli written fantasi nerd stu...s tacki bland like big bang theori probabl enjoy ', \"3.5 star found stori compel time label emot colo...i come term 's nice littl romanc brew stori well \", 'horribl soap opera void anyth alaska plot conclus reveal first chapter ', 'idea mani peopl gave book five star quick read c...like wast time reason finish book book club pick ', \"good surviv stori quit page-grip work boy bengal... ride extrem difficult condit 's worth read book \", 'dnf hate book read school bye ', 'slow bore far ', 'didn\\x92t like kept wait someth happen writer spent...ess want book end doesn\\x92t amazon give money back ', 'chapter 2 done book garbag ', \"n't like fact everyon 's point veiw kinda lost interest like book jump person person \", 'well go break ', 'pc suck jfc absolut sick death pc regim one oppr...h b far better literatur 21st centuri propaganda ', \"tri read finish read ca n't seem finish \", 'novel moment mainli descript alaska time letter ...hin due much predict novel progress banal surfac ', 'difficult book finish well written read first quarter rent movi finish may get book tape well ', 'audio version book dnf concept realli good listen half got bit gruesom shame want find happen ', ...], y=array([ 1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  ...,  0.,  1.,  0.,\n        0.,  0.,  0.,  0.,  0.]), scorer={'score': <function _passthrough_scorer>}, train=array([ 88,  90,  91,  92,  94,  95,  96,  97,  ..., 439, 440,\n       441, 442, 443, 444, 445, 446]), test=array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1..., 80, 81, 82, 83, 84,\n       85, 86, 87, 89, 93]), verbose=0, parameters={'clf__degree': 1, 'clf_nu__': 0.20000000000000001, 'tfidf__use_idf': True, 'vect__max_features': 15, 'vect__ngram_range': (1, 1)}, fit_params={}, return_train_score=True, return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    418                       for k, v in fit_params.items()])\n    419 \n    420     test_scores = {}\n    421     train_scores = {}\n    422     if parameters is not None:\n--> 423         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        parameters = {'clf__degree': 1, 'clf_nu__': 0.20000000000000001, 'tfidf__use_idf': True, 'vect__max_features': 15, 'vect__ngram_range': (1, 1)}\n    424 \n    425     start_time = time.time()\n    426 \n    427     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('vect', Count...e, shrinking=True,\n  tol=0.001, verbose=False))]), **kwargs={'clf__degree': 1, 'clf_nu__': 0.20000000000000001, 'tfidf__use_idf': True, 'vect__max_features': 15, 'vect__ngram_range': (1, 1)})\n    139 \n    140         Returns\n    141         -------\n    142         self\n    143         \"\"\"\n--> 144         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        kwargs = {'clf__degree': 1, 'clf_nu__': 0.20000000000000001, 'tfidf__use_idf': True, 'vect__max_features': 15, 'vect__ngram_range': (1, 1)}\n    145         return self\n    146 \n    147     def _validate_steps(self):\n    148         names, estimators = zip(*self.steps)\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('vect', Count...e, shrinking=True,\n  tol=0.001, verbose=False))]), attr='steps', **params={'clf__degree': 1, 'clf_nu__': 0.20000000000000001, 'tfidf__use_idf': True, 'vect__max_features': 15, 'vect__ngram_range': (1, 1)})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        params = {'clf__degree': 1, 'clf_nu__': 0.20000000000000001, 'tfidf__use_idf': True, 'vect__max_features': 15, 'vect__ngram_range': (1, 1)}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in set_params(self=Pipeline(memory=None,\n     steps=[('vect', Count...e, shrinking=True,\n  tol=0.001, verbose=False))]), **params={'clf__degree': 1, 'clf_nu__': 0.20000000000000001, 'tfidf__use_idf': True, 'vect__max_features': 15, 'vect__ngram_range': (1, 1)})\n    269                 name, sub_name = split\n    270                 if name not in valid_params:\n    271                     raise ValueError('Invalid parameter %s for estimator %s. '\n    272                                      'Check the list of available parameters '\n    273                                      'with `estimator.get_params().keys()`.' %\n--> 274                                      (name, self))\n        name = 'clf_nu'\n        self = Pipeline(memory=None,\n     steps=[('vect', Count...e, shrinking=True,\n  tol=0.001, verbose=False))])\n    275                 sub_object = valid_params[name]\n    276                 sub_object.set_params(**{sub_name: value})\n    277             else:\n    278                 # simple objects case\n\nValueError: Invalid parameter clf_nu for estimator Pipeline(memory=None,\n     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n        strip...,\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False))]). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 423, in _fit_and_score\n    estimator.set_params(**parameters)\n  File \"C:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 144, in set_params\n    self._set_params('steps', **kwargs)\n  File \"C:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 49, in _set_params\n    super(_BaseComposition, self).set_params(**params)\n  File \"C:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 274, in set_params\n    (name, self))\nValueError: Invalid parameter clf_nu for estimator Pipeline(memory=None,\n     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n        strip...,\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False))]). Check the list of available parameters with `estimator.get_params().keys()`.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\Aubrey\\Anaconda3\\lib\\multiprocessing\\pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"C:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Tue Oct 30 22:51:46 2018\nPID: 7424                Python 3.6.2: C:\\Users\\Aubrey\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('vect', Count...e, shrinking=True,\n  tol=0.001, verbose=False))]), ['noth read till 60 put sinc kept get wors oh well ', 'read 80 page book bore ', \"strongli dislik book clich fill stori 've encoun... bit silli 's definit least trope fill part book \", \"second chanc read still dnf could n't continu 'm...i 'll stand movi book n't interest well ... page \", 'basic list refer poorli written fantasi nerd stu...s tacki bland like big bang theori probabl enjoy ', \"3.5 star found stori compel time label emot colo...i come term 's nice littl romanc brew stori well \", 'horribl soap opera void anyth alaska plot conclus reveal first chapter ', 'idea mani peopl gave book five star quick read c...like wast time reason finish book book club pick ', \"good surviv stori quit page-grip work boy bengal... ride extrem difficult condit 's worth read book \", 'dnf hate book read school bye ', 'slow bore far ', 'didn\\x92t like kept wait someth happen writer spent...ess want book end doesn\\x92t amazon give money back ', 'chapter 2 done book garbag ', \"n't like fact everyon 's point veiw kinda lost interest like book jump person person \", 'well go break ', 'pc suck jfc absolut sick death pc regim one oppr...h b far better literatur 21st centuri propaganda ', \"tri read finish read ca n't seem finish \", 'novel moment mainli descript alaska time letter ...hin due much predict novel progress banal surfac ', 'difficult book finish well written read first quarter rent movi finish may get book tape well ', 'audio version book dnf concept realli good listen half got bit gruesom shame want find happen ', ...], array([ 1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  ...,  0.,  1.,  0.,\n        0.,  0.,  0.,  0.,  0.]), {'score': <function _passthrough_scorer>}, array([ 88,  90,  91,  92,  94,  95,  96,  97,  ..., 439, 440,\n       441, 442, 443, 444, 445, 446]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1..., 80, 81, 82, 83, 84,\n       85, 86, 87, 89, 93]), 0, {'clf__degree': 1, 'clf_nu__': 0.20000000000000001, 'tfidf__use_idf': True, 'vect__max_features': 15, 'vect__ngram_range': (1, 1)}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('vect', Count...e, shrinking=True,\n  tol=0.001, verbose=False))]), ['noth read till 60 put sinc kept get wors oh well ', 'read 80 page book bore ', \"strongli dislik book clich fill stori 've encoun... bit silli 's definit least trope fill part book \", \"second chanc read still dnf could n't continu 'm...i 'll stand movi book n't interest well ... page \", 'basic list refer poorli written fantasi nerd stu...s tacki bland like big bang theori probabl enjoy ', \"3.5 star found stori compel time label emot colo...i come term 's nice littl romanc brew stori well \", 'horribl soap opera void anyth alaska plot conclus reveal first chapter ', 'idea mani peopl gave book five star quick read c...like wast time reason finish book book club pick ', \"good surviv stori quit page-grip work boy bengal... ride extrem difficult condit 's worth read book \", 'dnf hate book read school bye ', 'slow bore far ', 'didn\\x92t like kept wait someth happen writer spent...ess want book end doesn\\x92t amazon give money back ', 'chapter 2 done book garbag ', \"n't like fact everyon 's point veiw kinda lost interest like book jump person person \", 'well go break ', 'pc suck jfc absolut sick death pc regim one oppr...h b far better literatur 21st centuri propaganda ', \"tri read finish read ca n't seem finish \", 'novel moment mainli descript alaska time letter ...hin due much predict novel progress banal surfac ', 'difficult book finish well written read first quarter rent movi finish may get book tape well ', 'audio version book dnf concept realli good listen half got bit gruesom shame want find happen ', ...], array([ 1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  ...,  0.,  1.,  0.,\n        0.,  0.,  0.,  0.,  0.]), {'score': <function _passthrough_scorer>}, array([ 88,  90,  91,  92,  94,  95,  96,  97,  ..., 439, 440,\n       441, 442, 443, 444, 445, 446]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1..., 80, 81, 82, 83, 84,\n       85, 86, 87, 89, 93]), 0, {'clf__degree': 1, 'clf_nu__': 0.20000000000000001, 'tfidf__use_idf': True, 'vect__max_features': 15, 'vect__ngram_range': (1, 1)})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('vect', Count...e, shrinking=True,\n  tol=0.001, verbose=False))]), X=['noth read till 60 put sinc kept get wors oh well ', 'read 80 page book bore ', \"strongli dislik book clich fill stori 've encoun... bit silli 's definit least trope fill part book \", \"second chanc read still dnf could n't continu 'm...i 'll stand movi book n't interest well ... page \", 'basic list refer poorli written fantasi nerd stu...s tacki bland like big bang theori probabl enjoy ', \"3.5 star found stori compel time label emot colo...i come term 's nice littl romanc brew stori well \", 'horribl soap opera void anyth alaska plot conclus reveal first chapter ', 'idea mani peopl gave book five star quick read c...like wast time reason finish book book club pick ', \"good surviv stori quit page-grip work boy bengal... ride extrem difficult condit 's worth read book \", 'dnf hate book read school bye ', 'slow bore far ', 'didn\\x92t like kept wait someth happen writer spent...ess want book end doesn\\x92t amazon give money back ', 'chapter 2 done book garbag ', \"n't like fact everyon 's point veiw kinda lost interest like book jump person person \", 'well go break ', 'pc suck jfc absolut sick death pc regim one oppr...h b far better literatur 21st centuri propaganda ', \"tri read finish read ca n't seem finish \", 'novel moment mainli descript alaska time letter ...hin due much predict novel progress banal surfac ', 'difficult book finish well written read first quarter rent movi finish may get book tape well ', 'audio version book dnf concept realli good listen half got bit gruesom shame want find happen ', ...], y=array([ 1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  ...,  0.,  1.,  0.,\n        0.,  0.,  0.,  0.,  0.]), scorer={'score': <function _passthrough_scorer>}, train=array([ 88,  90,  91,  92,  94,  95,  96,  97,  ..., 439, 440,\n       441, 442, 443, 444, 445, 446]), test=array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1..., 80, 81, 82, 83, 84,\n       85, 86, 87, 89, 93]), verbose=0, parameters={'clf__degree': 1, 'clf_nu__': 0.20000000000000001, 'tfidf__use_idf': True, 'vect__max_features': 15, 'vect__ngram_range': (1, 1)}, fit_params={}, return_train_score=True, return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    418                       for k, v in fit_params.items()])\n    419 \n    420     test_scores = {}\n    421     train_scores = {}\n    422     if parameters is not None:\n--> 423         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        parameters = {'clf__degree': 1, 'clf_nu__': 0.20000000000000001, 'tfidf__use_idf': True, 'vect__max_features': 15, 'vect__ngram_range': (1, 1)}\n    424 \n    425     start_time = time.time()\n    426 \n    427     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('vect', Count...e, shrinking=True,\n  tol=0.001, verbose=False))]), **kwargs={'clf__degree': 1, 'clf_nu__': 0.20000000000000001, 'tfidf__use_idf': True, 'vect__max_features': 15, 'vect__ngram_range': (1, 1)})\n    139 \n    140         Returns\n    141         -------\n    142         self\n    143         \"\"\"\n--> 144         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        kwargs = {'clf__degree': 1, 'clf_nu__': 0.20000000000000001, 'tfidf__use_idf': True, 'vect__max_features': 15, 'vect__ngram_range': (1, 1)}\n    145         return self\n    146 \n    147     def _validate_steps(self):\n    148         names, estimators = zip(*self.steps)\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('vect', Count...e, shrinking=True,\n  tol=0.001, verbose=False))]), attr='steps', **params={'clf__degree': 1, 'clf_nu__': 0.20000000000000001, 'tfidf__use_idf': True, 'vect__max_features': 15, 'vect__ngram_range': (1, 1)})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        params = {'clf__degree': 1, 'clf_nu__': 0.20000000000000001, 'tfidf__use_idf': True, 'vect__max_features': 15, 'vect__ngram_range': (1, 1)}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in set_params(self=Pipeline(memory=None,\n     steps=[('vect', Count...e, shrinking=True,\n  tol=0.001, verbose=False))]), **params={'clf__degree': 1, 'clf_nu__': 0.20000000000000001, 'tfidf__use_idf': True, 'vect__max_features': 15, 'vect__ngram_range': (1, 1)})\n    269                 name, sub_name = split\n    270                 if name not in valid_params:\n    271                     raise ValueError('Invalid parameter %s for estimator %s. '\n    272                                      'Check the list of available parameters '\n    273                                      'with `estimator.get_params().keys()`.' %\n--> 274                                      (name, self))\n        name = 'clf_nu'\n        self = Pipeline(memory=None,\n     steps=[('vect', Count...e, shrinking=True,\n  tol=0.001, verbose=False))])\n    275                 sub_object = valid_params[name]\n    276                 sub_object.set_params(**{sub_name: value})\n    277             else:\n    278                 # simple objects case\n\nValueError: Invalid parameter clf_nu for estimator Pipeline(memory=None,\n     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n        strip...,\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False))]). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Tue Oct 30 22:51:46 2018\nPID: 7424                Python 3.6.2: C:\\Users\\Aubrey\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('vect', Count...e, shrinking=True,\n  tol=0.001, verbose=False))]), ['noth read till 60 put sinc kept get wors oh well ', 'read 80 page book bore ', \"strongli dislik book clich fill stori 've encoun... bit silli 's definit least trope fill part book \", \"second chanc read still dnf could n't continu 'm...i 'll stand movi book n't interest well ... page \", 'basic list refer poorli written fantasi nerd stu...s tacki bland like big bang theori probabl enjoy ', \"3.5 star found stori compel time label emot colo...i come term 's nice littl romanc brew stori well \", 'horribl soap opera void anyth alaska plot conclus reveal first chapter ', 'idea mani peopl gave book five star quick read c...like wast time reason finish book book club pick ', \"good surviv stori quit page-grip work boy bengal... ride extrem difficult condit 's worth read book \", 'dnf hate book read school bye ', 'slow bore far ', 'didn\\x92t like kept wait someth happen writer spent...ess want book end doesn\\x92t amazon give money back ', 'chapter 2 done book garbag ', \"n't like fact everyon 's point veiw kinda lost interest like book jump person person \", 'well go break ', 'pc suck jfc absolut sick death pc regim one oppr...h b far better literatur 21st centuri propaganda ', \"tri read finish read ca n't seem finish \", 'novel moment mainli descript alaska time letter ...hin due much predict novel progress banal surfac ', 'difficult book finish well written read first quarter rent movi finish may get book tape well ', 'audio version book dnf concept realli good listen half got bit gruesom shame want find happen ', ...], array([ 1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  ...,  0.,  1.,  0.,\n        0.,  0.,  0.,  0.,  0.]), {'score': <function _passthrough_scorer>}, array([ 88,  90,  91,  92,  94,  95,  96,  97,  ..., 439, 440,\n       441, 442, 443, 444, 445, 446]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1..., 80, 81, 82, 83, 84,\n       85, 86, 87, 89, 93]), 0, {'clf__degree': 1, 'clf_nu__': 0.20000000000000001, 'tfidf__use_idf': True, 'vect__max_features': 15, 'vect__ngram_range': (1, 1)}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('vect', Count...e, shrinking=True,\n  tol=0.001, verbose=False))]), ['noth read till 60 put sinc kept get wors oh well ', 'read 80 page book bore ', \"strongli dislik book clich fill stori 've encoun... bit silli 's definit least trope fill part book \", \"second chanc read still dnf could n't continu 'm...i 'll stand movi book n't interest well ... page \", 'basic list refer poorli written fantasi nerd stu...s tacki bland like big bang theori probabl enjoy ', \"3.5 star found stori compel time label emot colo...i come term 's nice littl romanc brew stori well \", 'horribl soap opera void anyth alaska plot conclus reveal first chapter ', 'idea mani peopl gave book five star quick read c...like wast time reason finish book book club pick ', \"good surviv stori quit page-grip work boy bengal... ride extrem difficult condit 's worth read book \", 'dnf hate book read school bye ', 'slow bore far ', 'didn\\x92t like kept wait someth happen writer spent...ess want book end doesn\\x92t amazon give money back ', 'chapter 2 done book garbag ', \"n't like fact everyon 's point veiw kinda lost interest like book jump person person \", 'well go break ', 'pc suck jfc absolut sick death pc regim one oppr...h b far better literatur 21st centuri propaganda ', \"tri read finish read ca n't seem finish \", 'novel moment mainli descript alaska time letter ...hin due much predict novel progress banal surfac ', 'difficult book finish well written read first quarter rent movi finish may get book tape well ', 'audio version book dnf concept realli good listen half got bit gruesom shame want find happen ', ...], array([ 1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  ...,  0.,  1.,  0.,\n        0.,  0.,  0.,  0.,  0.]), {'score': <function _passthrough_scorer>}, array([ 88,  90,  91,  92,  94,  95,  96,  97,  ..., 439, 440,\n       441, 442, 443, 444, 445, 446]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1..., 80, 81, 82, 83, 84,\n       85, 86, 87, 89, 93]), 0, {'clf__degree': 1, 'clf_nu__': 0.20000000000000001, 'tfidf__use_idf': True, 'vect__max_features': 15, 'vect__ngram_range': (1, 1)})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('vect', Count...e, shrinking=True,\n  tol=0.001, verbose=False))]), X=['noth read till 60 put sinc kept get wors oh well ', 'read 80 page book bore ', \"strongli dislik book clich fill stori 've encoun... bit silli 's definit least trope fill part book \", \"second chanc read still dnf could n't continu 'm...i 'll stand movi book n't interest well ... page \", 'basic list refer poorli written fantasi nerd stu...s tacki bland like big bang theori probabl enjoy ', \"3.5 star found stori compel time label emot colo...i come term 's nice littl romanc brew stori well \", 'horribl soap opera void anyth alaska plot conclus reveal first chapter ', 'idea mani peopl gave book five star quick read c...like wast time reason finish book book club pick ', \"good surviv stori quit page-grip work boy bengal... ride extrem difficult condit 's worth read book \", 'dnf hate book read school bye ', 'slow bore far ', 'didn\\x92t like kept wait someth happen writer spent...ess want book end doesn\\x92t amazon give money back ', 'chapter 2 done book garbag ', \"n't like fact everyon 's point veiw kinda lost interest like book jump person person \", 'well go break ', 'pc suck jfc absolut sick death pc regim one oppr...h b far better literatur 21st centuri propaganda ', \"tri read finish read ca n't seem finish \", 'novel moment mainli descript alaska time letter ...hin due much predict novel progress banal surfac ', 'difficult book finish well written read first quarter rent movi finish may get book tape well ', 'audio version book dnf concept realli good listen half got bit gruesom shame want find happen ', ...], y=array([ 1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  ...,  0.,  1.,  0.,\n        0.,  0.,  0.,  0.,  0.]), scorer={'score': <function _passthrough_scorer>}, train=array([ 88,  90,  91,  92,  94,  95,  96,  97,  ..., 439, 440,\n       441, 442, 443, 444, 445, 446]), test=array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1..., 80, 81, 82, 83, 84,\n       85, 86, 87, 89, 93]), verbose=0, parameters={'clf__degree': 1, 'clf_nu__': 0.20000000000000001, 'tfidf__use_idf': True, 'vect__max_features': 15, 'vect__ngram_range': (1, 1)}, fit_params={}, return_train_score=True, return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    418                       for k, v in fit_params.items()])\n    419 \n    420     test_scores = {}\n    421     train_scores = {}\n    422     if parameters is not None:\n--> 423         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        parameters = {'clf__degree': 1, 'clf_nu__': 0.20000000000000001, 'tfidf__use_idf': True, 'vect__max_features': 15, 'vect__ngram_range': (1, 1)}\n    424 \n    425     start_time = time.time()\n    426 \n    427     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('vect', Count...e, shrinking=True,\n  tol=0.001, verbose=False))]), **kwargs={'clf__degree': 1, 'clf_nu__': 0.20000000000000001, 'tfidf__use_idf': True, 'vect__max_features': 15, 'vect__ngram_range': (1, 1)})\n    139 \n    140         Returns\n    141         -------\n    142         self\n    143         \"\"\"\n--> 144         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        kwargs = {'clf__degree': 1, 'clf_nu__': 0.20000000000000001, 'tfidf__use_idf': True, 'vect__max_features': 15, 'vect__ngram_range': (1, 1)}\n    145         return self\n    146 \n    147     def _validate_steps(self):\n    148         names, estimators = zip(*self.steps)\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('vect', Count...e, shrinking=True,\n  tol=0.001, verbose=False))]), attr='steps', **params={'clf__degree': 1, 'clf_nu__': 0.20000000000000001, 'tfidf__use_idf': True, 'vect__max_features': 15, 'vect__ngram_range': (1, 1)})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        params = {'clf__degree': 1, 'clf_nu__': 0.20000000000000001, 'tfidf__use_idf': True, 'vect__max_features': 15, 'vect__ngram_range': (1, 1)}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in set_params(self=Pipeline(memory=None,\n     steps=[('vect', Count...e, shrinking=True,\n  tol=0.001, verbose=False))]), **params={'clf__degree': 1, 'clf_nu__': 0.20000000000000001, 'tfidf__use_idf': True, 'vect__max_features': 15, 'vect__ngram_range': (1, 1)})\n    269                 name, sub_name = split\n    270                 if name not in valid_params:\n    271                     raise ValueError('Invalid parameter %s for estimator %s. '\n    272                                      'Check the list of available parameters '\n    273                                      'with `estimator.get_params().keys()`.' %\n--> 274                                      (name, self))\n        name = 'clf_nu'\n        self = Pipeline(memory=None,\n     steps=[('vect', Count...e, shrinking=True,\n  tol=0.001, verbose=False))])\n    275                 sub_object = valid_params[name]\n    276                 sub_object.set_params(**{sub_name: value})\n    277             else:\n    278                 # simple objects case\n\nValueError: Invalid parameter clf_nu for estimator Pipeline(memory=None,\n     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n        strip...,\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False))]). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-669f61581e5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m nsvc_clf = GridSearchCV(nsvc_clf, nsvcParams,\n\u001b[0;32m     13\u001b[0m                       cv=5, iid=False, n_jobs=-1)\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mnsvc_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnsvc_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainTxt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrTarg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnsvc_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnsvc_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    636\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    637\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 638\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    639\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x000000E5F37F0C90, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\A...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x000000E5F37F0C90, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\A...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'nsvcParams = {\"vect__ngram_range\": [(1, 1), (1, ...int(metrics.confusion_matrix(tsTarg, predicted))\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 10, 31, 3, 51, 45, 706495, tzinfo=tzutc()), 'msg_id': '5374905733F643A98B27158BFB560F81', 'msg_type': 'execute_request', 'session': '37C2346CBD894BB6AFC06AF5C68B8DE2', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '5374905733F643A98B27158BFB560F81', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'37C2346CBD894BB6AFC06AF5C68B8DE2']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'nsvcParams = {\"vect__ngram_range\": [(1, 1), (1, ...int(metrics.confusion_matrix(tsTarg, predicted))\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 10, 31, 3, 51, 45, 706495, tzinfo=tzutc()), 'msg_id': '5374905733F643A98B27158BFB560F81', 'msg_type': 'execute_request', 'session': '37C2346CBD894BB6AFC06AF5C68B8DE2', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '5374905733F643A98B27158BFB560F81', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'37C2346CBD894BB6AFC06AF5C68B8DE2'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'nsvcParams = {\"vect__ngram_range\": [(1, 1), (1, ...int(metrics.confusion_matrix(tsTarg, predicted))\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 10, 31, 3, 51, 45, 706495, tzinfo=tzutc()), 'msg_id': '5374905733F643A98B27158BFB560F81', 'msg_type': 'execute_request', 'session': '37C2346CBD894BB6AFC06AF5C68B8DE2', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '5374905733F643A98B27158BFB560F81', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='nsvcParams = {\"vect__ngram_range\": [(1, 1), (1, ...int(metrics.confusion_matrix(tsTarg, predicted))\\n', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'nsvcParams = {\"vect__ngram_range\": [(1, 1), (1, ...int(metrics.confusion_matrix(tsTarg, predicted))\\n'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('nsvcParams = {\"vect__ngram_range\": [(1, 1), (1, ...int(metrics.confusion_matrix(tsTarg, predicted))\\n',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('nsvcParams = {\"vect__ngram_range\": [(1, 1), (1, ...int(metrics.confusion_matrix(tsTarg, predicted))\\n',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='nsvcParams = {\"vect__ngram_range\": [(1, 1), (1, ...int(metrics.confusion_matrix(tsTarg, predicted))\\n', store_history=True, silent=False, shell_futures=True)\n   2693                 self.displayhook.exec_result = result\n   2694 \n   2695                 # Execute the user code\n   2696                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2697                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2698                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2699                 \n   2700                 self.last_execution_succeeded = not has_raised\n   2701 \n   2702                 # Reset this so later displayed values do not modify the\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>], cell_name='<ipython-input-33-669f61581e5d>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at e58032b0f0, execution..._before_exec=None error_in_exec=None result=None>)\n   2797 \n   2798         try:\n   2799             for i, node in enumerate(to_run_exec):\n   2800                 mod = ast.Module([node])\n   2801                 code = compiler(mod, cell_name, \"exec\")\n-> 2802                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x000000E5FFB47F60, file \"<ipython-input-33-669f61581e5d>\", line 14>\n        result = <ExecutionResult object at e58032b0f0, execution..._before_exec=None error_in_exec=None result=None>\n   2803                     return True\n   2804 \n   2805             for i, node in enumerate(to_run_interactive):\n   2806                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000000E5FFB47F60, file \"<ipython-input-33-669f61581e5d>\", line 14>, result=<ExecutionResult object at e58032b0f0, execution..._before_exec=None error_in_exec=None result=None>)\n   2857         outflag = True  # happens in more places, so it's easier as default\n   2858         try:\n   2859             try:\n   2860                 self.hooks.pre_run_code_hook()\n   2861                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2862                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x000000E5FFB47F60, file \"<ipython-input-33-669f61581e5d>\", line 14>\n        self.user_global_ns = {'BernoulliNB': <class 'sklearn.naive_bayes.BernoulliNB'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'FreqDist': <class 'nltk.probability.FreqDist'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import nltk\\nfrom nltk.corpus import stopwords\\nfr... import BernoulliNB\\n\\n\\nfrom sklearn import metrics', 'def getData():\\n    \\n    data = pd.read_csv(\"Book...s titles \"Unnamed\"\\n    \\n    return data\\n    \\n    ', 'def addPOS(df, ps):\\n    \\n    taggedTxt = []\\n    ...es(taggedTxt, index = df.index)\\n    return column', 'def tag_txt(txt, ps):\\n    #is passed a string of...taggedLst.append(word)\\n    \\n\\n    return taggedLst', 'def getFeatsCART(series):\\n    \\n    valList = []\\n...es(valList)\\n    \\n    return stemTxtCol\\n\\n    \\n    ', '\\nreviews = getData()\\nps = PorterStemmer()', 'reviews.loc[:, \"pos_stem\"] = addPOS(reviews.loc[...processed, tagged words as a new column of the df', 'reviews.loc[:, \"stemTxtCol\"] = getFeatsCART(reviews.loc[:, \\'pos_stem\\'])', 'txtList = [reviews.loc[:, \"stemTxtCol\"].iloc[i] ...rgArr[:piv]\\ntsTarg = targArr[piv:]\\n        \\n\\n    ', 'mnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2..._)\\nprint(randSearch.best_params_)\\nprint()\\nprint()', 'mnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'bnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'import nltk\\nfrom nltk.corpus import stopwords\\nfr...oulliNB, GaussianNB\\n\\n\\nfrom sklearn import metrics', 'def getData():\\n    \\n    data = pd.read_csv(\"Book...s titles \"Unnamed\"\\n    \\n    return data\\n    \\n    ', 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', ...], 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'NuSVC': <class 'sklearn.svm.classes.NuSVC'>, ...}\n        self.user_ns = {'BernoulliNB': <class 'sklearn.naive_bayes.BernoulliNB'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'FreqDist': <class 'nltk.probability.FreqDist'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import nltk\\nfrom nltk.corpus import stopwords\\nfr... import BernoulliNB\\n\\n\\nfrom sklearn import metrics', 'def getData():\\n    \\n    data = pd.read_csv(\"Book...s titles \"Unnamed\"\\n    \\n    return data\\n    \\n    ', 'def addPOS(df, ps):\\n    \\n    taggedTxt = []\\n    ...es(taggedTxt, index = df.index)\\n    return column', 'def tag_txt(txt, ps):\\n    #is passed a string of...taggedLst.append(word)\\n    \\n\\n    return taggedLst', 'def getFeatsCART(series):\\n    \\n    valList = []\\n...es(valList)\\n    \\n    return stemTxtCol\\n\\n    \\n    ', '\\nreviews = getData()\\nps = PorterStemmer()', 'reviews.loc[:, \"pos_stem\"] = addPOS(reviews.loc[...processed, tagged words as a new column of the df', 'reviews.loc[:, \"stemTxtCol\"] = getFeatsCART(reviews.loc[:, \\'pos_stem\\'])', 'txtList = [reviews.loc[:, \"stemTxtCol\"].iloc[i] ...rgArr[:piv]\\ntsTarg = targArr[piv:]\\n        \\n\\n    ', 'mnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2..._)\\nprint(randSearch.best_params_)\\nprint()\\nprint()', 'mnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'bnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'import nltk\\nfrom nltk.corpus import stopwords\\nfr...oulliNB, GaussianNB\\n\\n\\nfrom sklearn import metrics', 'def getData():\\n    \\n    data = pd.read_csv(\"Book...s titles \"Unnamed\"\\n    \\n    return data\\n    \\n    ', 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', 'gnbParams = {\"vect__ngram_range\": [(1, 1), (1, 2...rint(metrics.confusion_matrix(tsTarg, predicted))', ...], 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'NuSVC': <class 'sklearn.svm.classes.NuSVC'>, ...}\n   2863             finally:\n   2864                 # Reset our crash handler in place\n   2865                 sys.excepthook = old_excepthook\n   2866         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\Aubrey\\Documents\\BookReviews\\<ipython-input-33-669f61581e5d> in <module>()\n      9                      ('clf', SVC())])\n     10 \n     11 \n     12 nsvc_clf = GridSearchCV(nsvc_clf, nsvcParams,\n     13                       cv=5, iid=False, n_jobs=-1)\n---> 14 nsvc_clf = nsvc_clf.fit(trainTxt, trTarg)\n     15 print(nsvc_clf.best_score_)\n     16 print(nsvc_clf.best_params_) \n     17 \n     18 best = nsvc_clf.best_estimator_\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=0), X=['noth read till 60 put sinc kept get wors oh well ', 'read 80 page book bore ', \"strongli dislik book clich fill stori 've encoun... bit silli 's definit least trope fill part book \", \"second chanc read still dnf could n't continu 'm...i 'll stand movi book n't interest well ... page \", 'basic list refer poorli written fantasi nerd stu...s tacki bland like big bang theori probabl enjoy ', \"3.5 star found stori compel time label emot colo...i come term 's nice littl romanc brew stori well \", 'horribl soap opera void anyth alaska plot conclus reveal first chapter ', 'idea mani peopl gave book five star quick read c...like wast time reason finish book book club pick ', \"good surviv stori quit page-grip work boy bengal... ride extrem difficult condit 's worth read book \", 'dnf hate book read school bye ', 'slow bore far ', 'didn\\x92t like kept wait someth happen writer spent...ess want book end doesn\\x92t amazon give money back ', 'chapter 2 done book garbag ', \"n't like fact everyon 's point veiw kinda lost interest like book jump person person \", 'well go break ', 'pc suck jfc absolut sick death pc regim one oppr...h b far better literatur 21st centuri propaganda ', \"tri read finish read ca n't seem finish \", 'novel moment mainli descript alaska time letter ...hin due much predict novel progress banal surfac ', 'difficult book finish well written read first quarter rent movi finish may get book tape well ', 'audio version book dnf concept realli good listen half got bit gruesom shame want find happen ', ...], y=array([ 1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  ...,  0.,  1.,  0.,\n        0.,  0.,  0.,  0.,  0.]), groups=None, **fit_params={})\n    633                                   return_train_score=self.return_train_score,\n    634                                   return_n_test_samples=True,\n    635                                   return_times=True, return_parameters=False,\n    636                                   error_score=self.error_score)\n    637           for parameters, (train, test) in product(candidate_params,\n--> 638                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=5, random_state=None, shuffle=False)>\n        X = ['noth read till 60 put sinc kept get wors oh well ', 'read 80 page book bore ', \"strongli dislik book clich fill stori 've encoun... bit silli 's definit least trope fill part book \", \"second chanc read still dnf could n't continu 'm...i 'll stand movi book n't interest well ... page \", 'basic list refer poorli written fantasi nerd stu...s tacki bland like big bang theori probabl enjoy ', \"3.5 star found stori compel time label emot colo...i come term 's nice littl romanc brew stori well \", 'horribl soap opera void anyth alaska plot conclus reveal first chapter ', 'idea mani peopl gave book five star quick read c...like wast time reason finish book book club pick ', \"good surviv stori quit page-grip work boy bengal... ride extrem difficult condit 's worth read book \", 'dnf hate book read school bye ', 'slow bore far ', 'didn\\x92t like kept wait someth happen writer spent...ess want book end doesn\\x92t amazon give money back ', 'chapter 2 done book garbag ', \"n't like fact everyon 's point veiw kinda lost interest like book jump person person \", 'well go break ', 'pc suck jfc absolut sick death pc regim one oppr...h b far better literatur 21st centuri propaganda ', \"tri read finish read ca n't seem finish \", 'novel moment mainli descript alaska time letter ...hin due much predict novel progress banal surfac ', 'difficult book finish well written read first quarter rent movi finish may get book tape well ', 'audio version book dnf concept realli good listen half got bit gruesom shame want find happen ', ...]\n        y = array([ 1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  ...,  0.,  1.,  0.,\n        0.,  0.,  0.,  0.,  0.])\n        groups = None\n    639 \n    640         # if one choose to see train score, \"out\" will contain train score info\n    641         if self.return_train_score:\n    642             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Tue Oct 30 22:51:46 2018\nPID: 7424                Python 3.6.2: C:\\Users\\Aubrey\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('vect', Count...e, shrinking=True,\n  tol=0.001, verbose=False))]), ['noth read till 60 put sinc kept get wors oh well ', 'read 80 page book bore ', \"strongli dislik book clich fill stori 've encoun... bit silli 's definit least trope fill part book \", \"second chanc read still dnf could n't continu 'm...i 'll stand movi book n't interest well ... page \", 'basic list refer poorli written fantasi nerd stu...s tacki bland like big bang theori probabl enjoy ', \"3.5 star found stori compel time label emot colo...i come term 's nice littl romanc brew stori well \", 'horribl soap opera void anyth alaska plot conclus reveal first chapter ', 'idea mani peopl gave book five star quick read c...like wast time reason finish book book club pick ', \"good surviv stori quit page-grip work boy bengal... ride extrem difficult condit 's worth read book \", 'dnf hate book read school bye ', 'slow bore far ', 'didn\\x92t like kept wait someth happen writer spent...ess want book end doesn\\x92t amazon give money back ', 'chapter 2 done book garbag ', \"n't like fact everyon 's point veiw kinda lost interest like book jump person person \", 'well go break ', 'pc suck jfc absolut sick death pc regim one oppr...h b far better literatur 21st centuri propaganda ', \"tri read finish read ca n't seem finish \", 'novel moment mainli descript alaska time letter ...hin due much predict novel progress banal surfac ', 'difficult book finish well written read first quarter rent movi finish may get book tape well ', 'audio version book dnf concept realli good listen half got bit gruesom shame want find happen ', ...], array([ 1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  ...,  0.,  1.,  0.,\n        0.,  0.,  0.,  0.,  0.]), {'score': <function _passthrough_scorer>}, array([ 88,  90,  91,  92,  94,  95,  96,  97,  ..., 439, 440,\n       441, 442, 443, 444, 445, 446]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1..., 80, 81, 82, 83, 84,\n       85, 86, 87, 89, 93]), 0, {'clf__degree': 1, 'clf_nu__': 0.20000000000000001, 'tfidf__use_idf': True, 'vect__max_features': 15, 'vect__ngram_range': (1, 1)}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('vect', Count...e, shrinking=True,\n  tol=0.001, verbose=False))]), ['noth read till 60 put sinc kept get wors oh well ', 'read 80 page book bore ', \"strongli dislik book clich fill stori 've encoun... bit silli 's definit least trope fill part book \", \"second chanc read still dnf could n't continu 'm...i 'll stand movi book n't interest well ... page \", 'basic list refer poorli written fantasi nerd stu...s tacki bland like big bang theori probabl enjoy ', \"3.5 star found stori compel time label emot colo...i come term 's nice littl romanc brew stori well \", 'horribl soap opera void anyth alaska plot conclus reveal first chapter ', 'idea mani peopl gave book five star quick read c...like wast time reason finish book book club pick ', \"good surviv stori quit page-grip work boy bengal... ride extrem difficult condit 's worth read book \", 'dnf hate book read school bye ', 'slow bore far ', 'didn\\x92t like kept wait someth happen writer spent...ess want book end doesn\\x92t amazon give money back ', 'chapter 2 done book garbag ', \"n't like fact everyon 's point veiw kinda lost interest like book jump person person \", 'well go break ', 'pc suck jfc absolut sick death pc regim one oppr...h b far better literatur 21st centuri propaganda ', \"tri read finish read ca n't seem finish \", 'novel moment mainli descript alaska time letter ...hin due much predict novel progress banal surfac ', 'difficult book finish well written read first quarter rent movi finish may get book tape well ', 'audio version book dnf concept realli good listen half got bit gruesom shame want find happen ', ...], array([ 1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  ...,  0.,  1.,  0.,\n        0.,  0.,  0.,  0.,  0.]), {'score': <function _passthrough_scorer>}, array([ 88,  90,  91,  92,  94,  95,  96,  97,  ..., 439, 440,\n       441, 442, 443, 444, 445, 446]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1..., 80, 81, 82, 83, 84,\n       85, 86, 87, 89, 93]), 0, {'clf__degree': 1, 'clf_nu__': 0.20000000000000001, 'tfidf__use_idf': True, 'vect__max_features': 15, 'vect__ngram_range': (1, 1)})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('vect', Count...e, shrinking=True,\n  tol=0.001, verbose=False))]), X=['noth read till 60 put sinc kept get wors oh well ', 'read 80 page book bore ', \"strongli dislik book clich fill stori 've encoun... bit silli 's definit least trope fill part book \", \"second chanc read still dnf could n't continu 'm...i 'll stand movi book n't interest well ... page \", 'basic list refer poorli written fantasi nerd stu...s tacki bland like big bang theori probabl enjoy ', \"3.5 star found stori compel time label emot colo...i come term 's nice littl romanc brew stori well \", 'horribl soap opera void anyth alaska plot conclus reveal first chapter ', 'idea mani peopl gave book five star quick read c...like wast time reason finish book book club pick ', \"good surviv stori quit page-grip work boy bengal... ride extrem difficult condit 's worth read book \", 'dnf hate book read school bye ', 'slow bore far ', 'didn\\x92t like kept wait someth happen writer spent...ess want book end doesn\\x92t amazon give money back ', 'chapter 2 done book garbag ', \"n't like fact everyon 's point veiw kinda lost interest like book jump person person \", 'well go break ', 'pc suck jfc absolut sick death pc regim one oppr...h b far better literatur 21st centuri propaganda ', \"tri read finish read ca n't seem finish \", 'novel moment mainli descript alaska time letter ...hin due much predict novel progress banal surfac ', 'difficult book finish well written read first quarter rent movi finish may get book tape well ', 'audio version book dnf concept realli good listen half got bit gruesom shame want find happen ', ...], y=array([ 1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  ...,  0.,  1.,  0.,\n        0.,  0.,  0.,  0.,  0.]), scorer={'score': <function _passthrough_scorer>}, train=array([ 88,  90,  91,  92,  94,  95,  96,  97,  ..., 439, 440,\n       441, 442, 443, 444, 445, 446]), test=array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1..., 80, 81, 82, 83, 84,\n       85, 86, 87, 89, 93]), verbose=0, parameters={'clf__degree': 1, 'clf_nu__': 0.20000000000000001, 'tfidf__use_idf': True, 'vect__max_features': 15, 'vect__ngram_range': (1, 1)}, fit_params={}, return_train_score=True, return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    418                       for k, v in fit_params.items()])\n    419 \n    420     test_scores = {}\n    421     train_scores = {}\n    422     if parameters is not None:\n--> 423         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        parameters = {'clf__degree': 1, 'clf_nu__': 0.20000000000000001, 'tfidf__use_idf': True, 'vect__max_features': 15, 'vect__ngram_range': (1, 1)}\n    424 \n    425     start_time = time.time()\n    426 \n    427     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('vect', Count...e, shrinking=True,\n  tol=0.001, verbose=False))]), **kwargs={'clf__degree': 1, 'clf_nu__': 0.20000000000000001, 'tfidf__use_idf': True, 'vect__max_features': 15, 'vect__ngram_range': (1, 1)})\n    139 \n    140         Returns\n    141         -------\n    142         self\n    143         \"\"\"\n--> 144         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        kwargs = {'clf__degree': 1, 'clf_nu__': 0.20000000000000001, 'tfidf__use_idf': True, 'vect__max_features': 15, 'vect__ngram_range': (1, 1)}\n    145         return self\n    146 \n    147     def _validate_steps(self):\n    148         names, estimators = zip(*self.steps)\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('vect', Count...e, shrinking=True,\n  tol=0.001, verbose=False))]), attr='steps', **params={'clf__degree': 1, 'clf_nu__': 0.20000000000000001, 'tfidf__use_idf': True, 'vect__max_features': 15, 'vect__ngram_range': (1, 1)})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        params = {'clf__degree': 1, 'clf_nu__': 0.20000000000000001, 'tfidf__use_idf': True, 'vect__max_features': 15, 'vect__ngram_range': (1, 1)}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\nC:\\Users\\Aubrey\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in set_params(self=Pipeline(memory=None,\n     steps=[('vect', Count...e, shrinking=True,\n  tol=0.001, verbose=False))]), **params={'clf__degree': 1, 'clf_nu__': 0.20000000000000001, 'tfidf__use_idf': True, 'vect__max_features': 15, 'vect__ngram_range': (1, 1)})\n    269                 name, sub_name = split\n    270                 if name not in valid_params:\n    271                     raise ValueError('Invalid parameter %s for estimator %s. '\n    272                                      'Check the list of available parameters '\n    273                                      'with `estimator.get_params().keys()`.' %\n--> 274                                      (name, self))\n        name = 'clf_nu'\n        self = Pipeline(memory=None,\n     steps=[('vect', Count...e, shrinking=True,\n  tol=0.001, verbose=False))])\n    275                 sub_object = valid_params[name]\n    276                 sub_object.set_params(**{sub_name: value})\n    277             else:\n    278                 # simple objects case\n\nValueError: Invalid parameter clf_nu for estimator Pipeline(memory=None,\n     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n        strip...,\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False))]). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "nsvcParams = {\"vect__ngram_range\": [(1, 1), (1, 2), (1,3), (1,4)],\n",
    "            'vect__max_features': [i+15 for i in range(10)],\n",
    "            \"tfidf__use_idf\": (True, False), \n",
    "            \"clf__degree\": [i+1 for i in range(4)],\n",
    "             \"clf_nu__\": np.arange(.2, .9, .1)}\n",
    "\n",
    "nsvc_clf = Pipeline([('vect', CountVectorizer()), \n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SVC())])\n",
    "\n",
    "\n",
    "nsvc_clf = GridSearchCV(nsvc_clf, nsvcParams,\n",
    "                      cv=5, iid=False, n_jobs=-1)\n",
    "nsvc_clf = nsvc_clf.fit(trainTxt, trTarg)\n",
    "print(nsvc_clf.best_score_)\n",
    "print(nsvc_clf.best_params_) \n",
    "\n",
    "best = nsvc_clf.best_estimator_\n",
    "_ = best.fit(trainTxt, trTarg)\n",
    "\n",
    "predicted = best.predict(testTxt)\n",
    "\n",
    "\n",
    " \n",
    "# randSearch = RandomizedSearchCV(estimator = svc_clf, \n",
    "#                    param_distributions = svcParams,\n",
    "#                    n_iter = 100, cv = 3, verbose=2,\n",
    "#                    random_state=42, n_jobs = -1)\n",
    "# # Fit the random search model\n",
    "# randSearch.fit(trainTxt, trTarg)\n",
    "\n",
    "# best_random = randSearch.best_estimator_\n",
    "# # random_accuracy = evaluate(best_random, \n",
    "# #                            testTxt,\n",
    "# #                            tsTarg)\n",
    "\n",
    "# _ = best_random.fit(trainTxt, trTarg)\n",
    "\n",
    "# predicted = best_random.predict(testTxt)\n",
    "\n",
    "\n",
    "# print(randSearch.best_score_)\n",
    "# print(randSearch.best_params_)\n",
    "# print()\n",
    "# print()\n",
    "print()\n",
    "print()\n",
    "print(np.mean(predicted == tsTarg))\n",
    "print()\n",
    "print(\"classification report\")\n",
    "print(metrics.classification_report(tsTarg, predicted))\n",
    "print()\n",
    "print(\"confusion mtx\")\n",
    "print(metrics.confusion_matrix(tsTarg, predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.747052547951\n",
      "{'clf__loss': 'hinge', 'tfidf__use_idf': False, 'vect__max_features': 16, 'vect__ngram_range': (1, 4)}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-0fe85a161bfc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlsvc_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mbest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnsvc_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainTxt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrTarg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "lsvcParams = {\"vect__ngram_range\": [(1, 1), (1, 2), (1,3), (1,4)],\n",
    "            'vect__max_features': [i+15 for i in range(10)],\n",
    "            \"tfidf__use_idf\": (True, False), \n",
    "            \"clf__loss\": [\"hinge\", \"squared_hinge\"]}\n",
    "\n",
    "lsvc_clf = Pipeline([('vect', CountVectorizer()), \n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', LinearSVC())])\n",
    "\n",
    "\n",
    "lsvc_clf = GridSearchCV(lsvc_clf, lsvcParams,\n",
    "                      cv=5, iid=False, n_jobs=-1)\n",
    "lsvc_clf = lsvc_clf.fit(trainTxt, trTarg)\n",
    "print(lsvc_clf.best_score_)\n",
    "print(lsvc_clf.best_params_) \n",
    "\n",
    "best = nsvc_clf.best_estimator_\n",
    "_ = best.fit(trainTxt, trTarg)\n",
    "\n",
    "predicted = best.predict(testTxt)\n",
    "\n",
    "\n",
    " \n",
    "# randSearch = RandomizedSearchCV(estimator = svc_clf, \n",
    "#                    param_distributions = svcParams,\n",
    "#                    n_iter = 100, cv = 3, verbose=2,\n",
    "#                    random_state=42, n_jobs = -1)\n",
    "# # Fit the random search model\n",
    "# randSearch.fit(trainTxt, trTarg)\n",
    "\n",
    "# best_random = randSearch.best_estimator_\n",
    "# # random_accuracy = evaluate(best_random, \n",
    "# #                            testTxt,\n",
    "# #                            tsTarg)\n",
    "\n",
    "# _ = best_random.fit(trainTxt, trTarg)\n",
    "\n",
    "# predicted = best_random.predict(testTxt)\n",
    "\n",
    "\n",
    "# print(randSearch.best_score_)\n",
    "# print(randSearch.best_params_)\n",
    "# print()\n",
    "# print()\n",
    "print()\n",
    "print()\n",
    "print(np.mean(predicted == tsTarg))\n",
    "print()\n",
    "print(\"classification report\")\n",
    "print(metrics.classification_report(tsTarg, predicted))\n",
    "print()\n",
    "print(\"confusion mtx\")\n",
    "print(metrics.confusion_matrix(tsTarg, predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
